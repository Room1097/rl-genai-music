{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### starting with music 21 functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'music21.stream.base.Score'>\n",
      "<music21.chord.Chord C6 G5 E-5 C5>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\music_generator\\venv\\Lib\\site-packages\\music21\\stream\\base.py:3675: Music21DeprecationWarning: .flat is deprecated.  Call .flatten() instead\n",
      "  return self.iter().getElementsByClass(classFilterList)\n"
     ]
    }
   ],
   "source": [
    "import music21\n",
    "from music21 import *\n",
    "\n",
    "# load a midi file\n",
    "midi_file = music21.converter.parse('teddybear.mid')\n",
    "\n",
    "# print the type of the midi file\n",
    "print(type(midi_file))\n",
    "\n",
    "# print the first element of the midi file\n",
    "print(midi_file.flat.notes[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bach/bwv269\n",
      "bach/bwv347\n",
      "bach/bwv153.1\n",
      "bach/bwv86.6\n",
      "bach/bwv267\n",
      "bach/bwv281\n",
      "bach/bwv17.7\n",
      "bach/bwv40.8\n",
      "bach/bwv248.12-2\n",
      "bach/bwv38.6\n",
      "bach/bwv41.6\n",
      "bach/bwv65.2\n",
      "bach/bwv33.6\n",
      "bach/bwv184.5\n",
      "bach/bwv277\n",
      "bach/bwv311\n",
      "bach/bwv145.5\n",
      "bach/bwv318\n",
      "bach/bwv351\n",
      "bach/bwv302\n",
      "bach/bwv153.5\n",
      "bach/bwv180.7\n",
      "bach/bwv28.6\n",
      "bach/bwv415\n",
      "bach/bwv148.6\n",
      "bach/bwv20.11\n",
      "bach/bwv308\n",
      "bach/bwv36.8-2\n",
      "bach/bwv32.6\n",
      "bach/bwv363\n",
      "bach/bwv256\n",
      "bach/bwv386\n",
      "bach/bwv330\n",
      "bach/bwv305\n",
      "bach/bwv248.53-5\n",
      "bach/bwv385\n",
      "bach/bwv352\n",
      "bach/bwv115.6\n",
      "bach/bwv259\n",
      "bach/bwv255\n",
      "bach/bwv65.7\n",
      "bach/bwv67.7\n",
      "bach/bwv8.6\n",
      "bach/bwv377\n",
      "bach/bwv108.6\n",
      "bach/bwv248.9-1\n",
      "bach/bwv416\n",
      "bach/bwv26.6\n",
      "bach/bwv382\n",
      "bach/bwv244.37\n",
      "bach/bwv91.6\n",
      "bach/bwv429\n",
      "bach/bwv122.6\n",
      "bach/bwv151.5\n",
      "bach/bwv110.7\n",
      "bach/bwv121.6\n",
      "bach/bwv404\n",
      "bach/bwv174.5\n",
      "bach/bwv245.3\n",
      "bach/bwv133.6\n",
      "bach/bwv159.5\n",
      "bach/bwv197.10\n",
      "bach/bwv245.11\n",
      "bach/bwv194.6\n",
      "bach/bwv144.3\n",
      "bach/bwv280\n",
      "bach/bwv39.7\n",
      "bach/bwv431\n",
      "bach/bwv226.2\n",
      "bach/bwv322\n",
      "bach/bwv177.5\n",
      "bach/bwv6.6\n",
      "bach/bwv334\n",
      "bach/bwv244.54\n",
      "bach/bwv291\n",
      "bach/bwv30.6\n",
      "bach/bwv248.46-5\n",
      "bach/bwv244.3\n",
      "bach/bwv342\n",
      "bach/bwv244.44\n",
      "bach/bwv245.15\n",
      "bach/bwv46.6\n",
      "bach/bwv245.14\n",
      "bach/bwv197.5\n",
      "bach/bwv45.7\n",
      "bach/bwv36.4-2\n",
      "bach/bwv56.5\n",
      "bach/bwv28.6\n",
      "bach/bwv244.62\n",
      "bach/bwv57.8\n",
      "bach/bwv42.7\n",
      "bach/bwv168.6\n",
      "bach/bwv194.12\n",
      "bach/bwv47.5\n",
      "bach/bwv55.5\n",
      "bach/bwv87.7\n",
      "bach/bwv169.7\n",
      "bach/bwv244.15\n",
      "bach/bwv16.6\n",
      "bach/bwv18.5-w\n",
      "bach/bwv164.6\n",
      "bach/bwv43.11\n",
      "bach/bwv13.6\n",
      "bach/bwv88.7\n",
      "bach/bwv244.46\n",
      "bach/bwv245.28\n",
      "bach/bwv245.40\n",
      "bach/bwv245.26\n",
      "bach/bwv187.7\n",
      "bach/bwv102.7\n",
      "bach/bwv245.17\n",
      "bach/bwv84.5\n",
      "bach/bwv245.37\n",
      "bach/bwv419\n",
      "bach/bwv244.25\n",
      "bach/bwv29.8\n",
      "bach/bwv244.10\n",
      "bach/bwv244.32\n",
      "bach/bwv176.6\n",
      "bach/bwv103.6\n",
      "bach/bwv244.40\n",
      "bach/bwv85.6\n",
      "bach/bwv183.5\n",
      "bach/bwv268\n",
      "bach/bwv104.6\n",
      "bach/bwv18.5-l\n",
      "bach/bwv298\n",
      "bach/bwv263\n",
      "bach/bwv369\n",
      "bach/bwv324\n",
      "bach/bwv373\n",
      "bach/bwv371\n",
      "bach/bwv437\n",
      "bach/bwv301\n",
      "bach/bwv317\n",
      "bach/bwv332\n",
      "bach/bwv433\n",
      "bach/bwv64.8\n",
      "bach/bwv248.33-3\n",
      "bach/bwv367\n",
      "bach/bwv409\n",
      "bach/bwv40.6\n",
      "bach/bwv368\n",
      "bach/bwv339\n",
      "bach/bwv420\n",
      "bach/bwv434\n",
      "bach/bwv427\n",
      "bach/bwv414\n",
      "bach/bwv384\n",
      "bach/bwv27.6\n",
      "bach/bwv379\n",
      "bach/bwv154.8\n",
      "bach/bwv262\n",
      "bach/bwv293\n",
      "bach/bwv344\n",
      "bach/bwv3.6\n",
      "bach/bwv438\n",
      "bach/bwv294\n",
      "bach/bwv264\n",
      "bach/bwv64.2\n",
      "bach/bwv366\n",
      "bach/bwv288\n",
      "bach/bwv313\n",
      "bach/bwv326\n",
      "bach/bwv401\n",
      "bach/bwv309\n",
      "bach/bwv300\n",
      "bach/bwv341\n",
      "bach/bwv355\n",
      "bach/bwv62.6\n",
      "bach/bwv408\n",
      "bach/bwv410\n",
      "bach/bwv400\n",
      "bach/bwv364\n",
      "bach/bwv365\n",
      "bach/bwv306\n",
      "bach/bwv253\n",
      "bach/bwv122.6\n",
      "bach/bwv140.7\n",
      "bach/bwv265\n",
      "bach/bwv319\n",
      "bach/bwv14.5\n",
      "bach/bwv388\n",
      "bach/bwv4.8\n",
      "bach/bwv387\n",
      "bach/bwv254\n",
      "bach/bwv370\n",
      "bach/bwv349\n",
      "bach/bwv336\n",
      "bach/bwv337\n",
      "bach/bwv73.5\n",
      "bach/bwv321\n",
      "bach/bwv424\n",
      "bach/bwv123.6\n",
      "bach/bwv36.4-2\n",
      "bach/bwv285\n",
      "bach/bwv276\n",
      "bach/bwv283\n",
      "bach/bwv343\n",
      "bach/bwv284\n",
      "bach/bwv402\n",
      "bach/bwv407\n",
      "bach/bwv403\n",
      "bach/bwv166.6\n",
      "bach/bwv328\n",
      "bach/bwv412\n",
      "bach/bwv295\n",
      "bach/bwv266\n",
      "bach/bwv299\n",
      "bach/bwv275\n",
      "bach/bwv426\n",
      "bach/bwv329\n",
      "bach/bwv405\n",
      "bach/bwv383\n",
      "bach/bwv126.6\n",
      "bach/bwv60.5\n",
      "bach/bwv153.9\n",
      "bach/bwv372\n",
      "bach/bwv406\n",
      "bach/bwv413\n",
      "bach/bwv338\n",
      "bach/bwv391\n",
      "bach/bwv346\n",
      "bach/bwv290\n",
      "bach/bwv316\n",
      "bach/bwv333\n",
      "bach/bwv374\n",
      "bach/bwv286\n",
      "bach/bwv350\n",
      "bach/bwv273\n",
      "bach/bwv296\n",
      "bach/bwv297\n",
      "bach/bwv154.3\n",
      "bach/bwv320\n",
      "bach/bwv325\n",
      "bach/bwv335\n",
      "bach/bwv423\n",
      "bach/bwv310\n",
      "bach/bwv292\n",
      "bach/bwv396\n",
      "bach/bwv425\n",
      "bach/bwv435\n",
      "bach/bwv356\n",
      "bach/bwv357\n",
      "bach/bwv274\n",
      "bach/bwv411\n",
      "bach/bwv432\n",
      "bach/bwv177.4\n",
      "bach/bwv260\n",
      "bach/bwv303\n",
      "bach/bwv345\n",
      "bach/bwv362\n",
      "bach/bwv77.6\n",
      "bach/bwv25.6\n",
      "bach/bwv64.4\n",
      "bach/bwv194.6\n",
      "bach/bwv194.12\n",
      "bach/bwv378\n",
      "bach/bwv42.7\n",
      "bach/bwv307\n",
      "bach/bwv279\n",
      "bach/bwv2.6\n",
      "bach/bwv227.11\n",
      "bach/bwv361\n",
      "bach/bwv144.6\n",
      "bach/bwv48.7\n",
      "bach/bwv90.5\n",
      "bach/bwv389\n",
      "bach/bwv353\n",
      "bach/bwv161.6\n",
      "bach/bwv315\n",
      "bach/bwv348\n",
      "bach/bwv80.8\n",
      "bach/bwv397\n",
      "bach/bwv393\n",
      "bach/bwv375\n",
      "bach/bwv340\n",
      "bach/bwv436\n",
      "bach/bwv48.3\n",
      "bach/bwv304\n",
      "bach/bwv89.6\n",
      "bach/bwv25.6\n",
      "bach/bwv227.7\n",
      "bach/bwv127.5\n",
      "bach/bwv257\n",
      "bach/bwv270\n",
      "bach/bwv331\n",
      "bach/bwv314\n",
      "bach/bwv392\n",
      "bach/bwv9.7\n",
      "bach/bwv94.8\n",
      "bach/bwv101.7\n",
      "bach/bwv69.6-a\n",
      "bach/bwv113.8\n",
      "bach/bwv335\n",
      "bach/bwv390\n",
      "bach/bwv78.7\n",
      "bach/bwv19.7\n",
      "bach/bwv380\n",
      "bach/bwv421\n",
      "bach/bwv114.7\n",
      "bach/bwv343\n",
      "bach/bwv96.6\n",
      "bach/bwv5.7\n",
      "bach/bwv36.4-2\n",
      "bach/bwv402\n",
      "bach/bwv283\n",
      "bach/bwv3.6\n",
      "bach/bwv267\n",
      "bach/bwv245.22\n",
      "bach/bwv287\n",
      "bach/bwv398\n",
      "bach/bwv112.5\n",
      "bach/bwv289\n",
      "bach/bwv399\n",
      "bach/bwv282\n",
      "bach/bwv156.6\n",
      "bach/bwv339\n",
      "bach/bwv325\n",
      "bach/bwv323\n",
      "bach/bwv40.3\n",
      "bach/bwv428\n",
      "bach/bwv172.6\n",
      "bach/bwv81.7\n",
      "bach/bwv83.5\n",
      "bach/bwv104.6\n",
      "bach/bwv190.7\n",
      "bach/bwv373\n",
      "bach/bwv251\n",
      "bach/bwv252\n",
      "bach/bwv136.6\n",
      "bach/bwv418\n",
      "bach/bwv69.6\n",
      "bach/bwv327\n",
      "bach/bwv155.5\n",
      "bach/bwv258\n",
      "bach/bwv24.6\n",
      "bach/bwv145-a\n",
      "bach/bwv179.6\n",
      "bach/bwv272\n",
      "bach/bwv37.6\n",
      "bach/bwv376\n",
      "bach/bwv11.6\n",
      "bach/bwv248.23-2\n",
      "bach/bwv248.5\n",
      "bach/bwv381\n",
      "bach/bwv250\n",
      "bach/bwv70.11\n",
      "bach/bwv103.6\n",
      "bach/bwv360\n",
      "bach/bwv430\n",
      "bach/bwv312\n",
      "bach/bwv112.5\n",
      "bach/bwv117.4\n",
      "bach/bwv44.7\n",
      "bach/bwv358\n",
      "bach/bwv422\n",
      "bach/bwv10.7\n",
      "bach/bwv261\n",
      "bach/bwv248.35-3\n",
      "bach/bwv248.12-2\n",
      "bach/bwv248.59-6\n",
      "bach/bwv395\n",
      "bach/bwv417\n",
      "bach/bwv359\n",
      "bach/bwv394\n",
      "bach/bwv271\n",
      "bach/bwv248.42-4\n",
      "bach/bwv354\n",
      "bach/bwv74.8\n",
      "bach/bwv278\n"
     ]
    }
   ],
   "source": [
    "for chorale in corpus.chorales.Iterator(1,371,numberingSystem='riemenschneider',returnType='filename'):\n",
    "    print(chorale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chorale_stream = corpus.parse('bach/bwv66.6')  # Or use .chorales.Iterator()\n",
    "parts = chorale_stream.parts\n",
    "\n",
    "soprano_part = parts[0]\n",
    "alto_part = parts[1]\n",
    "tenor_part = parts[2]\n",
    "bass_part = parts[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 0 name: Soprano\n",
      "Instrument: P1: Soprano: Instrument 1\n",
      "Part 1 name: Alto\n",
      "Instrument: P2: Alto: Instrument 2\n",
      "Part 2 name: Tenor\n",
      "Instrument: P3: Tenor: Instrument 3\n",
      "Part 3 name: Bass\n",
      "Instrument: P4: Bass: Instrument 4\n"
     ]
    }
   ],
   "source": [
    "for i, part in enumerate(parts):\n",
    "    print(f\"Part {i} name:\", part.partName)\n",
    "    print(f\"Instrument:\", part.getInstrument())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv260135\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv260135_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv260135\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACJ2BNVHJrAAAAGgD/UQMJiWgA/1kCAwEA/1gEBAIYCM5g/y8ATVRyawAAAV8A/wMHU29wcmFubwDgAEAAwADOYJBJWqcwgEkAAJBHWqcwgEcAAJBFWs5ggEUAAJBHWs5ggEcAAJBJWs5ggEkAAJBMWs5ggEwAAJBJWs5ggEkAAJBHWs5ggEcAAJBFWs5ggEUAAJBJWs5ggEkAAJBFWqcwgEUAAJBHWqcwgEcAAJBEWs5ggEQAAJBCWs5ggEIAAJBFWs5ggEUAAJBHWs5ggEcAAJBHWs5ggEcAAJBCWs5ggEIAAJBAWs5ggEAAAJBFWs5ggEUAAJBHWs5ggEcAAJBJWs5ggEkAAJBJWs5ggEkAAJBFWs5ggEUAAJBHWs5ggEcAAJBJWs5ggEkAAJBFWs5ggEUAAJBEWs5ggEQAAJBCWs5ggEIAAJBEWoGdQIBEAACQQlqBnUCAQgAAkEJazmCAQgAAkEJagZ1AgEIAAJBCWqcwgEIAAJBBWqcwgEEAAJBCWs5ggEIAzmD/LwA=\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv260135_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv260135_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv260573\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv260573_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv260573\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACJ2BNVHJrAAAAGgD/UQMJiWgA/1kCAwEA/1gEBAIYCM5g/y8ATVRyawAAAZEA/wMEQWx0bwDhAEAAwQDOYJFAWs5ggUAAAJFCWs5ggUIAAJFAWs5ggUAAAJFAWs5ggUAAAJFAWs5ggUAAAJFAWqcwgUAAAJFFWqcwgUUAAJFEWs5ggUQAAJFAWs5ggUAAAJFEWs5ggUQAAJFCWqcwgUIAAJFEWqcwgUQAAJFBWs5ggUEAAJE9Ws5ggT0AAJFCWs5ggUIAAJFCWs5ggUIAAJFAWs5ggUAAAJE/Ws5ggT8AAJE9Ws5ggT0AAJE9WqcwgT0AAJFCWqcwgUIAAJFAWs5ggUAAAJFAWs5ggUAAAJFFWs5ggUUAAJFCWs5ggUIAAJFCWs5ggUIAAJFEWs5ggUQAAJFCWs5ggUIAAJFCWqcwgUIAAJFBWqcwgUEAAJFCWqcwgUIAAJE2WqcwgTYAAJE9WoGdQIE9AACRPVqnMIE9AACRPlqnMIE+AACRQFqBnUCBQAAAkT5apzCBPgAAkT1apzCBPQAAkTtapzCBOwAAkT1apzCBPQAAkT5azmCBPgAAkT1azmCBPQDOYP8vAA==\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv260573_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv260573_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv261084\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv261084_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv261084\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACJ2BNVHJrAAAAGgD/UQMJiWgA/1kCAwEA/1gEBAIYCM5g/y8ATVRyawAAAaQA/wMFVGVub3IA4gBAAMIAzmCSOVqnMII5AACSO1qnMII7AACSPVrOYII9AACSO1rOYII7AACSOVrOYII5AACSO1rOYII7AACSOVqnMII5AACSQFqnMIJAAACSQFqnMIJAAACSPlqnMII+AACSPVrOYII9AACSPVrOYII9AACSPVqnMII9AACSPlqnMII+AACSPVqnMII9AACSO1qnMII7AACSOVrOYII5AACSPVrOYII9AACSO1rOYII7AACSO1rOYII7AACSO1qnMII7AACSOVqnMII5AACSOFrOYII4AACSNlqnMII2AACSPlqnMII+AACSPVqnMII9AACSO1qnMII7AACSOVrOYII5AACSQFrOYIJAAACSPlrOYII+AACSPlrOYII+AACSPVrOYII9AACSPVrOYII9AACSPlqnMII+AACSPVrOYII9AACSO1qnMII7AACSNVqBnUCCNQAAkjZazmCCNgAAkj1agZ1Agj0AAJI7WqcwgjsAAJI6WqcwgjoAAJI7Ws5ggjsAAJI7Ws5ggjsAAJI6Ws5ggjoAzmD/LwA=\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv261084_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv261084_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv261514\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv261514_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv261514\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACJ2BNVHJrAAAAGgD/UQMJiWgA/1kCAwEA/1gEBAIYCM5g/y8ATVRyawAAAYgA/wMEQmFzcwDjAEAAwwDOYJM5WqcwgzkAAJM4WqcwgzgAAJM2Ws5ggzYAAJM4Ws5ggzgAAJM5Ws5ggzkAAJM4Ws5ggzgAAJM5WqcwgzkAAJMxWqcwgzEAAJM0Ws5ggzQAAJMtWs5ggy0AAJM1Ws5ggzUAAJM2WqcwgzYAAJMvWqcwgy8AAJMxWs5ggzEAAJMqWs5ggyoAAJM2Ws5ggzYAAJM4WqcwgzgAAJM2WqcwgzYAAJM4WqcwgzgAAJM5WqcwgzkAAJM7WqcwgzsAAJMvWqcwgy8AAJMxWs5ggzEAAJM2Ws5ggzYAAJM4Ws5ggzgAAJM5Ws5ggzkAAJM5Ws5ggzkAAJM+Ws5ggz4AAJM7Ws5ggzsAAJM1Ws5ggzUAAJM2Ws5ggzYAAJMvWqcwgy8AAJMxWqcwgzEAAJMyWs5ggzIAAJMxWoGdQIMxAACTLlqBnUCDLgAAky9azmCDLwAAkzFazmCDMQAAkzJazmCDMgAAky9azmCDLwAAkzZazmCDNgDOYP8vAA==\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv261514_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv261514_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from music21 import corpus\n",
    "\n",
    "chorale = corpus.parse('bach/bwv66.6')\n",
    "soprano = chorale.parts[0]\n",
    "alto = chorale.parts[1]\n",
    "tenor = chorale.parts[2]\n",
    "bass = chorale.parts[3]\n",
    "\n",
    "soprano.show('midi')  # Plays the soprano line\n",
    "alto.show('midi')\n",
    "tenor.show('midi')\n",
    "bass.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv263346\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv263346_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv263346\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,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\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv263346_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv263346_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chorale.show('midi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: C#5, Duration: 0.5, Offset: 0.0\n",
      "Note: B4, Duration: 0.5, Offset: 0.5\n",
      "Note: A4, Duration: 1.0, Offset: 0.0\n",
      "Note: B4, Duration: 1.0, Offset: 1.0\n",
      "Note: C#5, Duration: 1.0, Offset: 2.0\n",
      "Note: E5, Duration: 1.0, Offset: 3.0\n",
      "Note: C#5, Duration: 1.0, Offset: 0.0\n",
      "Note: B4, Duration: 1.0, Offset: 1.0\n",
      "Note: A4, Duration: 1.0, Offset: 2.0\n",
      "Note: C#5, Duration: 1.0, Offset: 3.0\n",
      "Note: A4, Duration: 0.5, Offset: 0.0\n",
      "Note: B4, Duration: 0.5, Offset: 0.5\n",
      "Note: G#4, Duration: 1.0, Offset: 1.0\n",
      "Note: F#4, Duration: 1.0, Offset: 2.0\n",
      "Note: A4, Duration: 1.0, Offset: 3.0\n",
      "Note: B4, Duration: 1.0, Offset: 0.0\n",
      "Note: B4, Duration: 1.0, Offset: 1.0\n",
      "Note: F#4, Duration: 1.0, Offset: 2.0\n",
      "Note: E4, Duration: 1.0, Offset: 3.0\n",
      "Note: A4, Duration: 1.0, Offset: 0.0\n",
      "Note: B4, Duration: 1.0, Offset: 1.0\n",
      "Note: C#5, Duration: 1.0, Offset: 2.0\n",
      "Note: C#5, Duration: 1.0, Offset: 3.0\n",
      "Note: A4, Duration: 1.0, Offset: 0.0\n",
      "Note: B4, Duration: 1.0, Offset: 1.0\n",
      "Note: C#5, Duration: 1.0, Offset: 2.0\n",
      "Note: A4, Duration: 1.0, Offset: 3.0\n",
      "Note: G#4, Duration: 1.0, Offset: 0.0\n",
      "Note: F#4, Duration: 1.0, Offset: 1.0\n",
      "Note: G#4, Duration: 2.0, Offset: 2.0\n",
      "Note: F#4, Duration: 2.0, Offset: 0.0\n",
      "Note: F#4, Duration: 1.0, Offset: 2.0\n",
      "Note: F#4, Duration: 1.0, Offset: 3.0\n",
      "Note: F#4, Duration: 1.0, Offset: 0.0\n",
      "Note: F#4, Duration: 0.5, Offset: 1.0\n",
      "Note: E#4, Duration: 0.5, Offset: 1.5\n",
      "Note: F#4, Duration: 1.0, Offset: 2.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for n in soprano.recurse().notes:\n",
    "    print(f\"Note: {n.pitch}, Duration: {n.quarterLength}, Offset: {n.offset}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import corpus, converter, note, chord\n",
    "\n",
    "chorales = corpus.chorales.Iterator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-hold: A3       | Subdivision: 1    ||   Single-hold: A3        \n",
      "Multi-hold: hold     | Subdivision: 2    ||   Single-hold: A3 hold   \n",
      "Multi-hold: B3       | Subdivision: 3    ||   Single-hold: B3        \n",
      "Multi-hold: hold     | Subdivision: 4    ||   Single-hold: B3 hold   \n",
      "Multi-hold: C#4      | Subdivision: 1    ||   Single-hold: C#4       \n",
      "Multi-hold: hold     | Subdivision: 2    ||   Single-hold: C#4 hold  \n",
      "Multi-hold: hold     | Subdivision: 3    ||   Single-hold: C#4 hold  \n",
      "Multi-hold: hold     | Subdivision: 4    ||   Single-hold: C#4 hold  \n",
      "Multi-hold: B3       | Subdivision: 1    ||   Single-hold: B3        \n",
      "Multi-hold: hold     | Subdivision: 2    ||   Single-hold: B3 hold   \n",
      "Multi-hold: hold     | Subdivision: 3    ||   Single-hold: B3 hold   \n",
      "Multi-hold: hold     | Subdivision: 4    ||   Single-hold: B3 hold   \n",
      "Multi-hold: A3       | Subdivision: 1    ||   Single-hold: A3        \n",
      "Multi-hold: hold     | Subdivision: 2    ||   Single-hold: A3 hold   \n",
      "Multi-hold: hold     | Subdivision: 3    ||   Single-hold: A3 hold   \n",
      "Multi-hold: hold     | Subdivision: 4    ||   Single-hold: A3 hold   \n"
     ]
    }
   ],
   "source": [
    "from music21 import corpus, note, stream, converter\n",
    "import numpy as np\n",
    "\n",
    "def extract_part_sequence(part, ticks_per_quarter=4, hold_type='multi'):\n",
    "    \"\"\"\n",
    "    Converts a part (e.g. soprano) into quantized time-step sequence.\n",
    "    hold_type: 'multi' or 'single'\n",
    "    \"\"\"\n",
    "    # Total duration in quarter notes\n",
    "    total_quarters = part.flat.highestTime\n",
    "    total_steps = int(total_quarters * ticks_per_quarter)\n",
    "\n",
    "    pitch_sequence = ['rest'] * total_steps\n",
    "    beat_sequence = [(i % ticks_per_quarter) + 1 for i in range(total_steps)]\n",
    "\n",
    "    for n in part.flat.notes:\n",
    "        pitch_name = n.pitch.nameWithOctave\n",
    "        start_step = int(n.offset * ticks_per_quarter)\n",
    "        duration_steps = int(n.quarterLength * ticks_per_quarter)\n",
    "\n",
    "        if hold_type == 'multi':\n",
    "            pitch_sequence[start_step] = pitch_name\n",
    "            for i in range(1, duration_steps):\n",
    "                if start_step + i < total_steps:\n",
    "                    pitch_sequence[start_step + i] = 'hold'\n",
    "\n",
    "        elif hold_type == 'single':\n",
    "            pitch_sequence[start_step] = pitch_name\n",
    "            for i in range(1, duration_steps):\n",
    "                if start_step + i < total_steps:\n",
    "                    pitch_sequence[start_step + i] = f\"{pitch_name} hold\"\n",
    "\n",
    "    return pitch_sequence, beat_sequence\n",
    "\n",
    "# === Example usage ===\n",
    "\n",
    "# Load a Bach chorale\n",
    "chorale = corpus.parse('bach/bwv66.6')\n",
    "soprano = chorale.parts[0]# or alto/tenor/bass\n",
    "alto = chorale.parts[1]\n",
    "tenor = chorale.parts[2]\n",
    "bass = chorale.parts[3]\n",
    "\n",
    "# Choose representation\n",
    "multi_pitch, multi_beat = extract_part_sequence(tenor, hold_type='multi')\n",
    "single_pitch, single_beat = extract_part_sequence(tenor, hold_type='single')\n",
    "\n",
    "\n",
    "# Show first few steps\n",
    "for i in range(16):\n",
    "    print(f\"Multi-hold: {multi_pitch[i]:<8} | Subdivision: {multi_beat[i]}    ||   Single-hold: {single_pitch[i]:<10}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### store in .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from music21 import corpus\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def extract_part_sequence(part, ticks_per_quarter=4, hold_type='single'):\n",
    "#     total_quarters = part.flat.highestTime\n",
    "#     total_steps = int(total_quarters * ticks_per_quarter)\n",
    "#     pitch_sequence = ['rest'] * total_steps\n",
    "#     beat_sequence = [(i % ticks_per_quarter) + 1 for i in range(total_steps)]\n",
    "\n",
    "#     for n in part.flat.notes:\n",
    "#         pitch_name = n.pitch.nameWithOctave\n",
    "#         start_step = int(n.offset * ticks_per_quarter)\n",
    "#         duration_steps = int(n.quarterLength * ticks_per_quarter)\n",
    "#         pitch_sequence[start_step] = pitch_name\n",
    "#         for i in range(1, duration_steps):\n",
    "#             if start_step + i < total_steps:\n",
    "#                 pitch_sequence[start_step + i] = 'hold' if hold_type == 'multi' else f\"{pitch_name} hold\"\n",
    "#     return pitch_sequence, beat_sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_bach_dataset_json(output_path='bach_chorales_full.json', ticks_per_quarter=4):\n",
    "#     dataset = []\n",
    "#     chorales = list(corpus.chorales.Iterator())\n",
    "#     excluded_chorales = []  # List to store chorales that are excluded\n",
    "\n",
    "#     for idx, score in enumerate(tqdm(chorales, desc=\"Processing chorales\")):\n",
    "#         try:\n",
    "#             parts = score.parts\n",
    "#             if len(parts) < 4:\n",
    "#                 print(f\"Skipping chorale {idx}: Not enough parts\")\n",
    "#                 excluded_chorales.append(idx)\n",
    "#                 continue\n",
    "\n",
    "#             chorale_entry = {'chorale_id': idx}\n",
    "#             is_out_of_range = False \n",
    "\n",
    "#             for voice_name, part in zip(['soprano', 'alto', 'tenor', 'bass'], parts[:4]):\n",
    "#                 pitch_multi, beat_multi = extract_part_sequence(part, ticks_per_quarter, hold_type='multi')\n",
    "#                 pitch_single, beat_single = extract_part_sequence(part, ticks_per_quarter, hold_type='single')\n",
    "\n",
    "#                 # Check if any note in the part is out of range (MIDI number outside 36 to 81)\n",
    "#                 for n in part.flat.notes:\n",
    "#                     if not (36 <= n.pitch.midi <= 81):\n",
    "#                         is_out_of_range = True\n",
    "#                         break  \n",
    "\n",
    "#                 chorale_entry[voice_name] = {\n",
    "#                     'multi': {'pitch': pitch_multi, 'beat': beat_multi},\n",
    "#                     'single': {'pitch': pitch_single, 'beat': beat_single}\n",
    "#                 }\n",
    "\n",
    "            \n",
    "#             if is_out_of_range:\n",
    "#                 excluded_chorales.append(idx)\n",
    "#                 print(f\"Excluding chorale {idx}: Contains notes out of range!\")\n",
    "#                 continue \n",
    "\n",
    "#             dataset.append(chorale_entry)\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"Skipping chorale {idx}: {e}\")\n",
    "#             excluded_chorales.append(idx)\n",
    "\n",
    "#     with open(output_path, 'w') as f:\n",
    "#         json.dump(dataset, f)\n",
    "\n",
    "#     print(f\"✅ Saved {len(dataset)} chorales to {output_path}\")\n",
    "#     print(f\"🚫 Excluded chorales: {excluded_chorales}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chorales:  19%|█▉        | 70/371 [00:00<00:02, 134.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping chorale 45: 'Chord' object has no attribute 'pitch'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chorales:  35%|███▌      | 131/371 [00:00<00:01, 137.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding chorale 115: Contains notes out of range!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chorales:  80%|███████▉  | 295/371 [00:02<00:00, 126.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding chorale 269: Contains notes out of range!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chorales:  87%|████████▋ | 322/371 [00:02<00:00, 119.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding chorale 297: Contains notes out of range!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chorales:  95%|█████████▍| 352/371 [00:02<00:00, 130.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding chorale 322: Contains notes out of range!\n",
      "Excluding chorale 326: Contains notes out of range!\n",
      "Excluding chorale 330: Contains notes out of range!\n",
      "Excluding chorale 343: Contains notes out of range!\n",
      "Excluding chorale 347: Contains notes out of range!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chorales: 100%|██████████| 371/371 [00:02<00:00, 130.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding chorale 367: Contains notes out of range!\n",
      " Saved 361 chorales to bach_chorales_full.json\n",
      " Excluded chorales: [45, 115, 269, 297, 322, 326, 330, 343, 347, 367]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from music21 import corpus\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dynamically build the pitch vocab during dataset creation\n",
    "def extract_part_sequence(part, ticks_per_quarter=4, hold_type='single', pitch_vocab_single=None, pitch_vocab_multi=None):\n",
    "    total_quarters = part.flat.highestTime\n",
    "    total_steps = int(total_quarters * ticks_per_quarter)\n",
    "    pitch_sequence = ['rest'] * total_steps\n",
    "    beat_sequence = [(i % ticks_per_quarter) + 1 for i in range(total_steps)]\n",
    "\n",
    "    for n in part.flat.notes:\n",
    "        pitch_name = n.pitch.nameWithOctave\n",
    "        \n",
    "        # Handle pitch vocab for single encoding\n",
    "        if hold_type == 'single':\n",
    "            pitch_name_single = f\"{pitch_name} hold\"\n",
    "            if pitch_name not in pitch_vocab_single:\n",
    "                pitch_vocab_single[pitch_name] = len(pitch_vocab_single)\n",
    "            if pitch_name_single not in pitch_vocab_single:\n",
    "                pitch_vocab_single[pitch_name_single] = len(pitch_vocab_single)\n",
    "        \n",
    "        # Handle pitch vocab for multi encoding\n",
    "        elif hold_type == 'multi':\n",
    "            if pitch_name not in pitch_vocab_multi:\n",
    "                pitch_vocab_multi[pitch_name] = len(pitch_vocab_multi)\n",
    "            if 'hold' not in pitch_vocab_multi:\n",
    "                pitch_vocab_multi['hold'] = len(pitch_vocab_multi)\n",
    "        \n",
    "        start_step = int(n.offset * ticks_per_quarter)\n",
    "        duration_steps = int(n.quarterLength * ticks_per_quarter)\n",
    "        pitch_sequence[start_step] = pitch_name\n",
    "        \n",
    "        for i in range(1, duration_steps):\n",
    "            if start_step + i < total_steps:\n",
    "                if hold_type == 'multi':\n",
    "                    pitch_sequence[start_step + i] = 'hold'\n",
    "                else:\n",
    "                    pitch_sequence[start_step + i] = f\"{pitch_name} hold\"\n",
    "    \n",
    "    return pitch_sequence, beat_sequence\n",
    "\n",
    "# Function to prepare dataset and create pitch vocab\n",
    "def prepare_bach_dataset_json(output_path='bach_chorales_full.json', ticks_per_quarter=4):\n",
    "    dataset = []\n",
    "    pitch_vocab_single = {'PAD': 0, 'rest': 1}  # Initialize the vocab for single encoding with PAD=0 and rest=1\n",
    "    pitch_vocab_multi = {'PAD': 0, 'rest': 1}   # Initialize the vocab for multi encoding with PAD=0 and rest=1\n",
    "\n",
    "    chorales = list(corpus.chorales.Iterator())\n",
    "    excluded_chorales = []  # List to store chorales that are excluded\n",
    "\n",
    "    for idx, score in enumerate(tqdm(chorales, desc=\"Processing chorales\")):\n",
    "        try:\n",
    "            parts = score.parts\n",
    "            if len(parts) < 4:\n",
    "                print(f\"Skipping chorale {idx}: Not enough parts\")\n",
    "                excluded_chorales.append(idx)\n",
    "                continue\n",
    "\n",
    "            chorale_entry = {'chorale_id': idx}\n",
    "            is_out_of_range = False \n",
    "\n",
    "            for voice_name, part in zip(['soprano', 'alto', 'tenor', 'bass'], parts[:4]):\n",
    "                pitch_multi, beat_multi = extract_part_sequence(part, ticks_per_quarter, hold_type='multi', \n",
    "                                                                pitch_vocab_single=pitch_vocab_single, \n",
    "                                                                pitch_vocab_multi=pitch_vocab_multi)\n",
    "                pitch_single, beat_single = extract_part_sequence(part, ticks_per_quarter, hold_type='single', \n",
    "                                                                 pitch_vocab_single=pitch_vocab_single, \n",
    "                                                                 pitch_vocab_multi=pitch_vocab_multi)\n",
    "\n",
    "                # Check if any note in the part is out of range (MIDI number outside 36 to 81)\n",
    "                for n in part.flat.notes:\n",
    "                    if not (36 <= n.pitch.midi <= 81):\n",
    "                        is_out_of_range = True\n",
    "                        break  \n",
    "\n",
    "                chorale_entry[voice_name] = {\n",
    "                    'multi': {'pitch': pitch_multi, 'beat': beat_multi},\n",
    "                    'single': {'pitch': pitch_single, 'beat': beat_single}\n",
    "                }\n",
    "\n",
    "            if is_out_of_range:\n",
    "                excluded_chorales.append(idx)\n",
    "                print(f\"Excluding chorale {idx}: Contains notes out of range!\")\n",
    "                continue \n",
    "\n",
    "            dataset.append(chorale_entry)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping chorale {idx}: {e}\")\n",
    "            excluded_chorales.append(idx)\n",
    "\n",
    "    # Save the dataset as JSON\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(dataset, f)\n",
    "\n",
    "    print(f\" Saved {len(dataset)} chorales to {output_path}\")\n",
    "    print(f\" Excluded chorales: {excluded_chorales}\")\n",
    "\n",
    "    # Return both pitch vocabularies (the dictionary of all encountered pitches for both single and multi)\n",
    "    return pitch_vocab_single, pitch_vocab_multi\n",
    "\n",
    "# Call the function to generate the dataset and the pitch vocabularies\n",
    "pitch_vocab_single, pitch_vocab_multi = prepare_bach_dataset_json(output_path='bach_chorales_full.json', ticks_per_quarter=4)\n",
    "\n",
    "# You can save the pitch vocabularies to separate files if needed\n",
    "with open('pitch_vocab_single.json', 'w') as f:\n",
    "    json.dump(pitch_vocab_single, f)\n",
    "\n",
    "with open('pitch_vocab_multi.json', 'w') as f:\n",
    "    json.dump(pitch_vocab_multi, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_bach_dataset_json()  # This creates 'bach_chorales_full.json'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train -> 300 and test -> 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def split_dataset_deterministic(input_path='bach_chorales_full.json', train_count=300, train_path='bach_train.json', test_path='bach_test.json'):\n",
    "    with open(input_path, 'r') as f:\n",
    "        full_data = json.load(f)\n",
    "\n",
    "    train_data = full_data[:train_count]\n",
    "    test_data = full_data[train_count:]\n",
    "\n",
    "    with open(train_path, 'w') as f:\n",
    "        json.dump(train_data, f, indent=2)\n",
    "    with open(test_path, 'w') as f:\n",
    "        json.dump(test_data, f, indent=2)\n",
    "\n",
    "    print(f\" Saved {len(train_data)} training samples to {train_path}\")\n",
    "    print(f\" Saved {len(test_data)} testing samples to {test_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved 300 training samples to bach_train.json\n",
      " Saved 61 testing samples to bach_test.json\n"
     ]
    }
   ],
   "source": [
    "split_dataset_deterministic()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_bach_datasets(train_path='bach_train.json', test_path='bach_test.json'):\n",
    "    with open(train_path, 'r') as f:\n",
    "        train_data = json.load(f)\n",
    "    with open(test_path, 'r') as f:\n",
    "        test_data = json.load(f)\n",
    "    \n",
    "    print(f\" Loaded {len(train_data)} training samples\")\n",
    "    print(f\" Loaded {len(test_data)} testing samples\")\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 300 training samples\n",
      " Loaded 61 testing samples\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = load_bach_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import stream, note, meter\n",
    "\n",
    "def sequence_to_stream(pitch_seq, beat_seq, ticks_per_quarter=4, is_single_hold=False):\n",
    "    \"\"\"\n",
    "    Convert a pitch sequence and beat sequence back into a music21 stream.Part.\n",
    "    \"\"\"\n",
    "    s = stream.Part()\n",
    "    s.append(meter.TimeSignature('4/4'))  # optional, makes visualization easier\n",
    "    \n",
    "    current_pitch = None\n",
    "    duration = 0.0\n",
    "    step_duration = 1.0 / ticks_per_quarter  # e.g., 0.25 for 16th note\n",
    "\n",
    "    for i, pitch in enumerate(pitch_seq):\n",
    "        if is_single_hold and \"hold\" in pitch:\n",
    "            duration += step_duration\n",
    "        elif pitch == 'hold':\n",
    "            duration += step_duration\n",
    "        else:\n",
    "            # End previous note\n",
    "            if current_pitch:\n",
    "                if current_pitch == 'rest':\n",
    "                    s.append(note.Rest(quarterLength=duration))\n",
    "                else:\n",
    "                    s.append(note.Note(current_pitch, quarterLength=duration))\n",
    "            # Start new note\n",
    "            current_pitch = pitch\n",
    "            duration = step_duration\n",
    "\n",
    "    # Append final note\n",
    "    if current_pitch:\n",
    "        if current_pitch == 'rest':\n",
    "            s.append(note.Rest(quarterLength=duration))\n",
    "        else:\n",
    "            s.append(note.Note(current_pitch, quarterLength=duration))\n",
    "    \n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['chorale_id', 'soprano', 'alto', 'tenor', 'bass'])\n",
      "dict_keys(['multi', 'single'])\n",
      "dict_keys(['pitch', 'beat'])\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0].keys())\n",
    "print(train_data[0]['soprano'].keys())\n",
    "print(train_data[0]['soprano']['multi'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv1247886\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv1247886_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv1247886\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACJ2BNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCM5g/y8ATVRyawAAAbwA/wMAAOAAQM5gkENazmCAQwAAkENagZ1AgEMAAJBKWs5ggEoAAJBHWvYQgEcAAJBFWqcwgEUAAJBDWs5ggEMAAJBDWvYQgEMAAJBFWqcwgEUAAJBHWs5ggEcAAJBFWoGdQIBFAACQR1rOYIBHAACQSlqBnUCASgAAkEhazmCASAAAkEdazmCARwAAkEVagZ1AgEUAAJBDWoGdQIBDAACQR1rOYIBHAACQR1rOYIBHAACQSFrOYIBIAACQSlrOYIBKAACQSlr2EIBKAACQSFqnMIBIAACQR1rOYIBHAACQRVqBnUCARQAAkENazmCAQwAAkEdagZ1AgEcAAJBIWs5ggEgAAJBKWoGdQIBKAACQSFrOYIBIAACQR1qB7CCARwAAkENagZ1AgEMAAJBHWs5ggEcAAJBKWoGdQIBKAACQSFrOYIBIAACQR1qBnUCARwAAkEVazmCARQAAkENa9hCAQwAAkEVapzCARQAAkEdazmCARwAAkEVagZ1AgEUAAJBHWs5ggEcAAJBKWoGdQIBKAACQSFrOYIBIAACQR1rOYIBHAACQRVqBnUCARQAAkENagZ1AgEMAzmD/LwA=\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv1247886_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv1247886_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = train_data[0]  # or test_data[0]\n",
    "\n",
    "reconstructed_stream = sequence_to_stream(\n",
    "    sample['soprano']['multi']['pitch'],\n",
    "    sample['soprano']['multi']['beat'],\n",
    "    is_single_hold=False  # change to True for single-hold representation\n",
    ")\n",
    "\n",
    "reconstructed_stream.show('midi')  # or use .show() or .show('midi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: G4, Duration: 1.0, Offset: 0.0\n",
      "Note: G4, Duration: 2.0, Offset: 1.0\n",
      "Note: D5, Duration: 1.0, Offset: 3.0\n",
      "Note: B4, Duration: 1.5, Offset: 4.0\n",
      "Note: A4, Duration: 0.5, Offset: 5.5\n",
      "Note: G4, Duration: 1.0, Offset: 6.0\n",
      "Note: G4, Duration: 1.5, Offset: 7.0\n",
      "Note: A4, Duration: 0.5, Offset: 8.5\n",
      "Note: B4, Duration: 1.0, Offset: 9.0\n",
      "Note: A4, Duration: 2.0, Offset: 10.0\n",
      "Note: B4, Duration: 1.0, Offset: 12.0\n",
      "Note: D5, Duration: 2.0, Offset: 13.0\n",
      "Note: C5, Duration: 1.0, Offset: 15.0\n",
      "Note: B4, Duration: 1.0, Offset: 16.0\n",
      "Note: A4, Duration: 2.0, Offset: 17.0\n",
      "Note: G4, Duration: 2.0, Offset: 19.0\n",
      "Note: B4, Duration: 1.0, Offset: 21.0\n",
      "Note: B4, Duration: 1.0, Offset: 22.0\n",
      "Note: C5, Duration: 1.0, Offset: 23.0\n",
      "Note: D5, Duration: 1.0, Offset: 24.0\n",
      "Note: D5, Duration: 1.5, Offset: 25.0\n",
      "Note: C5, Duration: 0.5, Offset: 26.5\n",
      "Note: B4, Duration: 1.0, Offset: 27.0\n",
      "Note: A4, Duration: 2.0, Offset: 28.0\n",
      "Note: G4, Duration: 1.0, Offset: 30.0\n",
      "Note: B4, Duration: 2.0, Offset: 31.0\n",
      "Note: C5, Duration: 1.0, Offset: 33.0\n",
      "Note: D5, Duration: 2.0, Offset: 34.0\n",
      "Note: C5, Duration: 1.0, Offset: 36.0\n",
      "Note: B4, Duration: 3.0, Offset: 37.0\n",
      "Note: G4, Duration: 2.0, Offset: 40.0\n",
      "Note: B4, Duration: 1.0, Offset: 42.0\n",
      "Note: D5, Duration: 2.0, Offset: 43.0\n",
      "Note: C5, Duration: 1.0, Offset: 45.0\n",
      "Note: B4, Duration: 2.0, Offset: 46.0\n",
      "Note: A4, Duration: 1.0, Offset: 48.0\n",
      "Note: G4, Duration: 1.5, Offset: 49.0\n",
      "Note: A4, Duration: 0.5, Offset: 50.5\n",
      "Note: B4, Duration: 1.0, Offset: 51.0\n",
      "Note: A4, Duration: 2.0, Offset: 52.0\n",
      "Note: B4, Duration: 1.0, Offset: 54.0\n",
      "Note: D5, Duration: 2.0, Offset: 55.0\n",
      "Note: C5, Duration: 1.0, Offset: 57.0\n",
      "Note: B4, Duration: 1.0, Offset: 58.0\n",
      "Note: A4, Duration: 2.0, Offset: 59.0\n",
      "Note: G4, Duration: 2.0, Offset: 61.0\n"
     ]
    }
   ],
   "source": [
    "for n in reconstructed_stream.recurse().notes:\n",
    "    print(f\"Note: {n.pitch}, Duration: {n.quarterLength}, Offset: {n.offset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def prepare_duet_dataset(json_path, num_duets=5, encoding_type='multi'):\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        chorales = json.load(f)\n",
    "\n",
    "    part_pairs = [(a, b) for a in ['soprano', 'alto', 'tenor', 'bass'] for b in ['soprano', 'alto', 'tenor', 'bass'] if a != b]\n",
    "    \n",
    "    max_unique = len(chorales) * len(part_pairs)\n",
    "    if num_duets > max_unique:\n",
    "        raise ValueError(f\"Requested {num_duets} duets, but only {max_unique} unique combinations are possible.\")\n",
    "\n",
    "    duets = []\n",
    "    seen = set() \n",
    "\n",
    "    while len(duets) < num_duets:\n",
    "        chorale = random.choice(chorales)\n",
    "        human_part, machine_part = random.sample(['soprano', 'alto', 'tenor', 'bass'], 2)\n",
    "\n",
    "        key = (chorale['chorale_id'], human_part, machine_part, encoding_type)\n",
    "        if key in seen:\n",
    "            continue  \n",
    "\n",
    "        try:\n",
    "            human_filtered = list(zip(chorale[human_part][encoding_type]['pitch'], chorale[human_part][encoding_type]['beat']))\n",
    "            machine_filtered = list(zip(chorale[machine_part][encoding_type]['pitch'], chorale[machine_part][encoding_type]['beat']))\n",
    "        except KeyError:\n",
    "            continue \n",
    "\n",
    "        min_len = min(len(human_filtered), len(machine_filtered))\n",
    "        if min_len == 0:\n",
    "            continue  \n",
    "\n",
    "        human_filtered = human_filtered[:min_len]\n",
    "        machine_filtered = machine_filtered[:min_len]\n",
    "\n",
    "        human_pitches = [p for p, _ in human_filtered]\n",
    "        machine_pitches = [p for p, _ in machine_filtered]\n",
    "        beats = [b for _, b in human_filtered]\n",
    "\n",
    "        duet = {\n",
    "            'chorale_id': chorale['chorale_id'],\n",
    "            'human_part': human_part,\n",
    "            'machine_part': machine_part,\n",
    "            'encoding': encoding_type,\n",
    "            'human': {'pitch': human_pitches},\n",
    "            'machine': {'pitch': machine_pitches},\n",
    "            'beat': beats\n",
    "        }\n",
    "\n",
    "        duets.append(duet)\n",
    "        seen.add(key)\n",
    "\n",
    "    return duets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beat': [1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4,\n",
      "          1,\n",
      "          2,\n",
      "          3,\n",
      "          4],\n",
      " 'chorale_id': 21,\n",
      " 'encoding': 'single',\n",
      " 'human': {'pitch': ['F3',\n",
      "                     'F3 hold',\n",
      "                     'F3 hold',\n",
      "                     'F3 hold',\n",
      "                     'C3',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'D3',\n",
      "                     'D3 hold',\n",
      "                     'D3 hold',\n",
      "                     'D3 hold',\n",
      "                     'E3',\n",
      "                     'E3 hold',\n",
      "                     'E3 hold',\n",
      "                     'E3 hold',\n",
      "                     'F3',\n",
      "                     'F3 hold',\n",
      "                     'F3 hold',\n",
      "                     'F3 hold',\n",
      "                     'A2',\n",
      "                     'A2 hold',\n",
      "                     'B-2',\n",
      "                     'B-2 hold',\n",
      "                     'C3',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'F2',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'E3',\n",
      "                     'E3 hold',\n",
      "                     'E3 hold',\n",
      "                     'E3 hold',\n",
      "                     'F3',\n",
      "                     'F3 hold',\n",
      "                     'F3 hold',\n",
      "                     'F3 hold',\n",
      "                     'D3',\n",
      "                     'D3 hold',\n",
      "                     'E3',\n",
      "                     'E3 hold',\n",
      "                     'F3',\n",
      "                     'F3 hold',\n",
      "                     'F3 hold',\n",
      "                     'F3 hold',\n",
      "                     'B-2',\n",
      "                     'B-2 hold',\n",
      "                     'B-2 hold',\n",
      "                     'B-2 hold',\n",
      "                     'A2',\n",
      "                     'A2 hold',\n",
      "                     'B-2',\n",
      "                     'B-2 hold',\n",
      "                     'C3',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'F2',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F3',\n",
      "                     'F3 hold',\n",
      "                     'F3 hold',\n",
      "                     'F3 hold',\n",
      "                     'E3',\n",
      "                     'E3 hold',\n",
      "                     'E3 hold',\n",
      "                     'E3 hold',\n",
      "                     'D3',\n",
      "                     'D3 hold',\n",
      "                     'E3',\n",
      "                     'E3 hold',\n",
      "                     'F3',\n",
      "                     'F3 hold',\n",
      "                     'G3',\n",
      "                     'G3 hold',\n",
      "                     'A3',\n",
      "                     'A3 hold',\n",
      "                     'A3 hold',\n",
      "                     'A3 hold',\n",
      "                     'A3 hold',\n",
      "                     'A3 hold',\n",
      "                     'G3',\n",
      "                     'G3 hold',\n",
      "                     'F3',\n",
      "                     'F3 hold',\n",
      "                     'F3 hold',\n",
      "                     'F3 hold',\n",
      "                     'G3',\n",
      "                     'G3 hold',\n",
      "                     'G3 hold',\n",
      "                     'G3 hold',\n",
      "                     'C3',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'F3',\n",
      "                     'F3 hold',\n",
      "                     'F3 hold',\n",
      "                     'F3 hold',\n",
      "                     'B-2',\n",
      "                     'B-2 hold',\n",
      "                     'B-2 hold',\n",
      "                     'B-2 hold',\n",
      "                     'A2',\n",
      "                     'A2 hold',\n",
      "                     'G2',\n",
      "                     'G2 hold',\n",
      "                     'A2',\n",
      "                     'A2 hold',\n",
      "                     'B2',\n",
      "                     'B2 hold',\n",
      "                     'C3',\n",
      "                     'C3 hold',\n",
      "                     'D3',\n",
      "                     'D3 hold',\n",
      "                     'E3',\n",
      "                     'E3 hold',\n",
      "                     'F3',\n",
      "                     'F3 hold',\n",
      "                     'G3',\n",
      "                     'G3 hold',\n",
      "                     'G3 hold',\n",
      "                     'G3 hold',\n",
      "                     'G2',\n",
      "                     'G2 hold',\n",
      "                     'G2 hold',\n",
      "                     'G2 hold',\n",
      "                     'C3',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C4',\n",
      "                     'C4 hold',\n",
      "                     'C4 hold',\n",
      "                     'C4 hold',\n",
      "                     'B-3',\n",
      "                     'B-3 hold',\n",
      "                     'A3',\n",
      "                     'A3 hold',\n",
      "                     'G3',\n",
      "                     'G3 hold',\n",
      "                     'G3 hold',\n",
      "                     'G3 hold',\n",
      "                     'F3',\n",
      "                     'F3 hold',\n",
      "                     'E3',\n",
      "                     'E3 hold',\n",
      "                     'F3',\n",
      "                     'F3 hold',\n",
      "                     'F3 hold',\n",
      "                     'F3 hold',\n",
      "                     'B-2',\n",
      "                     'B-2 hold',\n",
      "                     'B-2 hold',\n",
      "                     'B-2 hold',\n",
      "                     'C3',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'A2',\n",
      "                     'A2 hold',\n",
      "                     'A2 hold',\n",
      "                     'A2 hold',\n",
      "                     'D3',\n",
      "                     'D3 hold',\n",
      "                     'D3 hold',\n",
      "                     'D3 hold',\n",
      "                     'G2',\n",
      "                     'G2 hold',\n",
      "                     'G2 hold',\n",
      "                     'G2 hold',\n",
      "                     'A2',\n",
      "                     'A2 hold',\n",
      "                     'A2 hold',\n",
      "                     'A2 hold',\n",
      "                     'B-2',\n",
      "                     'B-2 hold',\n",
      "                     'B-2 hold',\n",
      "                     'B-2 hold',\n",
      "                     'A2',\n",
      "                     'A2 hold',\n",
      "                     'B-2',\n",
      "                     'B-2 hold',\n",
      "                     'C3',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'C3 hold',\n",
      "                     'F2',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold',\n",
      "                     'F2 hold']},\n",
      " 'human_part': 'bass',\n",
      " 'machine': {'pitch': ['C4',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'B-3',\n",
      "                       'B-3 hold',\n",
      "                       'A3',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'G3',\n",
      "                       'G3 hold',\n",
      "                       'G3 hold',\n",
      "                       'G3 hold',\n",
      "                       'F3',\n",
      "                       'F3 hold',\n",
      "                       'G3',\n",
      "                       'G3 hold',\n",
      "                       'A3',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'G3',\n",
      "                       'G3 hold',\n",
      "                       'F3',\n",
      "                       'F3 hold',\n",
      "                       'G3',\n",
      "                       'G3 hold',\n",
      "                       'G3 hold',\n",
      "                       'G3 hold',\n",
      "                       'F3',\n",
      "                       'F3 hold',\n",
      "                       'F3 hold',\n",
      "                       'F3 hold',\n",
      "                       'F3 hold',\n",
      "                       'F3 hold',\n",
      "                       'F3 hold',\n",
      "                       'F3 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'D4',\n",
      "                       'D4 hold',\n",
      "                       'D4 hold',\n",
      "                       'D4 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'D4',\n",
      "                       'D4 hold',\n",
      "                       'D4 hold',\n",
      "                       'D4 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'B-3',\n",
      "                       'A3',\n",
      "                       'B-3',\n",
      "                       'B-3 hold',\n",
      "                       'B-3 hold',\n",
      "                       'B-3 hold',\n",
      "                       'A3',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'F4',\n",
      "                       'F4 hold',\n",
      "                       'F4 hold',\n",
      "                       'F4 hold',\n",
      "                       'B3',\n",
      "                       'B3 hold',\n",
      "                       'C#4',\n",
      "                       'C#4 hold',\n",
      "                       'D4',\n",
      "                       'D4 hold',\n",
      "                       'D4 hold',\n",
      "                       'D4 hold',\n",
      "                       'D4',\n",
      "                       'D4 hold',\n",
      "                       'D4 hold',\n",
      "                       'D4 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'B3',\n",
      "                       'B3 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'B3',\n",
      "                       'B3 hold',\n",
      "                       'B3 hold',\n",
      "                       'B3 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'A3',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'B-3',\n",
      "                       'B-3 hold',\n",
      "                       'B-3 hold',\n",
      "                       'B-3 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'B3',\n",
      "                       'B3 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'D4',\n",
      "                       'D4 hold',\n",
      "                       'E4',\n",
      "                       'E4 hold',\n",
      "                       'F4',\n",
      "                       'F4 hold',\n",
      "                       'G4',\n",
      "                       'G4 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'B3',\n",
      "                       'B3 hold',\n",
      "                       'B3 hold',\n",
      "                       'B3 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'B-3',\n",
      "                       'B-3 hold',\n",
      "                       'A3',\n",
      "                       'A3 hold',\n",
      "                       'G3',\n",
      "                       'G3 hold',\n",
      "                       'G3 hold',\n",
      "                       'G3 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'D4',\n",
      "                       'D4 hold',\n",
      "                       'D4 hold',\n",
      "                       'D4 hold',\n",
      "                       'E4',\n",
      "                       'E4 hold',\n",
      "                       'D4',\n",
      "                       'D4 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'B-3',\n",
      "                       'B-3 hold',\n",
      "                       'B-3 hold',\n",
      "                       'B-3 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'D4',\n",
      "                       'D4 hold',\n",
      "                       'D4 hold',\n",
      "                       'D4 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4 hold',\n",
      "                       'C4',\n",
      "                       'C4 hold',\n",
      "                       'B-3',\n",
      "                       'A3',\n",
      "                       'B-3',\n",
      "                       'B-3 hold',\n",
      "                       'B-3 hold',\n",
      "                       'B-3 hold',\n",
      "                       'A3',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold',\n",
      "                       'A3 hold']},\n",
      " 'machine_part': 'tenor'}\n"
     ]
    }
   ],
   "source": [
    "json_path = \"bach_train.json\"\n",
    "\n",
    "num_duets = 5\n",
    "\n",
    "encoding = \"single\"\n",
    "\n",
    "duet_samples = prepare_duet_dataset(json_path, num_duets=num_duets, encoding_type=encoding)\n",
    "\n",
    "# Print one sample nicely\n",
    "import pprint\n",
    "pprint.pprint(duet_samples[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import note\n",
    "PITCH_VOCAB_SINGLE = pitch_vocab_single  \n",
    "PITCH_VOCAB_MULTI = pitch_vocab_multi  \n",
    "\n",
    "\n",
    "\n",
    "INV_PITCH_VOCAB_SINGLE = {v: k for k, v in PITCH_VOCAB_SINGLE.items()}\n",
    "INV_PITCH_VOCAB_MULTI = {v: k for k, v in PITCH_VOCAB_MULTI.items()}\n",
    "\n",
    "\n",
    "def encode_pitch(pitch_str, encoding='single'):\n",
    "    if encoding == 'single':\n",
    "        return PITCH_VOCAB_SINGLE[pitch_str]\n",
    "    elif encoding == 'multi':\n",
    "        return PITCH_VOCAB_MULTI[pitch_str]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown encoding type: {encoding}\")\n",
    "\n",
    "def decode_pitch(token_id, encoding='single'):\n",
    "    if encoding == 'single':\n",
    "        return INV_PITCH_VOCAB_SINGLE[token_id]  # The inverse vocab works for both\n",
    "    elif encoding == 'multi':\n",
    "        return INV_PITCH_VOCAB_MULTI[token_id]  # The inverse vocab works for both\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown encoding type: {encoding}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "class DuetDataset(Dataset):\n",
    "    def __init__(self, duet_data, encoding='single'):\n",
    "        self.duet_data = duet_data\n",
    "        self.encoding = encoding\n",
    "        self.pitch_vocab = PITCH_VOCAB_SINGLE\n",
    "        self.inv_pitch_vocab = INV_PITCH_VOCAB_SINGLE\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.duet_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.duet_data[idx]\n",
    "        human_pitch = [self.pitch_vocab[p] for p in entry['human']['pitch']]\n",
    "        machine_pitch = [self.pitch_vocab[p] for p in entry['machine']['pitch']]\n",
    "        beat = entry['beat']\n",
    "        length = min(len(human_pitch), len(machine_pitch), len(beat))\n",
    "        return {\n",
    "            'human_pitch': torch.tensor(human_pitch[:length], dtype=torch.long),\n",
    "            'machine_pitch': torch.tensor(machine_pitch[:length], dtype=torch.long),\n",
    "            'beat': torch.tensor(beat[:length], dtype=torch.float),\n",
    "        }\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return len(self.pitch_vocab)\n",
    "\n",
    "\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "PAD_IDX = pitch_vocab_single['PAD']  \n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    human_seqs = [item['human_pitch'] for item in batch]\n",
    "    machine_seqs = [item['machine_pitch'] for item in batch]\n",
    "    beat_seqs = [item['beat'] for item in batch]  \n",
    "\n",
    "    human_lengths = torch.tensor([len(seq) for seq in human_seqs])\n",
    "    machine_lengths = torch.tensor([len(seq) for seq in machine_seqs])\n",
    "\n",
    "    human_padded = pad_sequence(human_seqs, batch_first=True, padding_value=PAD_IDX)\n",
    "    machine_padded = pad_sequence(machine_seqs, batch_first=True, padding_value=PAD_IDX)\n",
    "    beat_padded = pad_sequence(beat_seqs, batch_first=True, padding_value=PAD_IDX)\n",
    "\n",
    "    return {\n",
    "        'human_pitch': human_padded,\n",
    "        'machine_pitch': machine_padded,\n",
    "        'human_lengths': human_lengths,\n",
    "        'machine_lengths': machine_lengths,\n",
    "        'beat': beat_padded  \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_duet_data(json_path, num_samples=100, encoding='single'):\n",
    "    with open(json_path) as f:\n",
    "        chorales = json.load(f)\n",
    "    all_duets = prepare_duet_dataset(json_path, num_samples, encoding)\n",
    "    return DuetDataset(all_duets, encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "\n",
    "    def step(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "\n",
    "        if self.counter >= self.patience:\n",
    "            return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BaseRewardModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_size=128, dropout_prob=0.3, use_beat=True):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.use_beat = use_beat\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if self.use_beat:\n",
    "            self.beat_embedding = nn.Embedding(100, embedding_dim)\n",
    "            self.beat_rnn = nn.GRU(embedding_dim, hidden_size, batch_first=True)\n",
    "\n",
    "class JointRewardModel(BaseRewardModel):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_size=128, dropout_prob=0.3, use_beat=True, **kwargs):\n",
    "        super().__init__(vocab_size, embedding_dim, hidden_size, dropout_prob, use_beat)\n",
    "        self.fc = nn.Linear(self.hidden_size * 5, 1)\n",
    "\n",
    "    def forward(self, human, human_lengths, machine, machine_lengths, beat):\n",
    "        human_emb = self.embedding(human)\n",
    "        machine_emb = self.embedding(machine)\n",
    "\n",
    "        human_packed = nn.utils.rnn.pack_padded_sequence(human_emb, human_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        machine_packed = nn.utils.rnn.pack_padded_sequence(machine_emb, machine_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        _, human_hidden = self.gru(human_packed)\n",
    "        _, machine_hidden = self.gru(machine_packed)\n",
    "\n",
    "        human_hidden = torch.cat([human_hidden[-2], human_hidden[-1]], dim=1)\n",
    "        machine_hidden = torch.cat([machine_hidden[-2], machine_hidden[-1]], dim=1)\n",
    "\n",
    "        if self.use_beat:\n",
    "            beat_emb = self.beat_embedding(beat)  \n",
    "            beat_out, _ = self.beat_rnn(beat_emb)\n",
    "            beat_feat = beat_out[:, -1, :]\n",
    "            beat_feat = self.dropout(beat_feat)\n",
    "        else:\n",
    "            beat_feat = torch.zeros(human_hidden.size(0), self.hidden_size, device=human.device)\n",
    "\n",
    "        combined = torch.cat([\n",
    "            self.dropout(human_hidden),\n",
    "            self.dropout(machine_hidden),\n",
    "            beat_feat\n",
    "        ], dim=1)\n",
    "\n",
    "        return self.fc(combined).squeeze(1)\n",
    "\n",
    "\n",
    "class JointRangeRewardModel(BaseRewardModel):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_size=128, dropout_prob=0.3, use_beat=True, **kwargs):\n",
    "        super().__init__(vocab_size, embedding_dim, hidden_size, dropout_prob, use_beat)\n",
    "        self.fc = nn.Linear(self.hidden_size * 3, 1)\n",
    "\n",
    "    def forward(self, human, human_lengths, machine, machine_lengths, beat):\n",
    "        full_input = torch.cat([human, machine], dim=1)\n",
    "        full_lengths = human_lengths + machine_lengths\n",
    "\n",
    "        emb = self.embedding(full_input)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(emb, full_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, hidden = self.gru(packed)\n",
    "        joint_hidden = torch.cat([hidden[-2], hidden[-1]], dim=1)\n",
    "\n",
    "        if self.use_beat:\n",
    "            beat_emb = self.beat_embedding(beat)  \n",
    "            beat_out, _ = self.beat_rnn(beat_emb)\n",
    "            beat_feat = self.dropout(beat_out[:, -1, :])\n",
    "        else:\n",
    "            beat_feat = torch.zeros(joint_hidden.size(0), self.hidden_size, device=joint_hidden.device)\n",
    "\n",
    "        combined = torch.cat([\n",
    "            self.dropout(joint_hidden),\n",
    "            beat_feat\n",
    "        ], dim=1)\n",
    "\n",
    "        return self.fc(combined).squeeze(1)\n",
    "\n",
    "\n",
    "class HorizontalRewardModel(BaseRewardModel):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_size=128, dropout_prob=0.3, use_beat=True, **kwargs):\n",
    "        super().__init__(vocab_size, embedding_dim, hidden_size, dropout_prob, use_beat)\n",
    "        self.fc = nn.Linear(self.hidden_size * 3, 1)\n",
    "\n",
    "    def forward(self, human, human_lengths, machine, machine_lengths, beat):\n",
    "        machine_emb = self.embedding(machine)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(machine_emb, machine_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, machine_hidden = self.gru(packed)\n",
    "        machine_hidden = torch.cat([machine_hidden[-2], machine_hidden[-1]], dim=1)\n",
    "\n",
    "        if self.use_beat:\n",
    "            beat_emb = self.beat_embedding(beat)  \n",
    "            beat_out, _ = self.beat_rnn(beat_emb)\n",
    "            beat_feat = self.dropout(beat_out[:, -1, :])\n",
    "        else:\n",
    "            beat_feat = torch.zeros(machine_hidden.size(0), self.hidden_size, device=machine.device)\n",
    "\n",
    "        combined = torch.cat([\n",
    "            self.dropout(machine_hidden),\n",
    "            beat_feat\n",
    "        ], dim=1)\n",
    "\n",
    "        return self.fc(combined).squeeze(1)\n",
    "\n",
    "\n",
    "\n",
    "class VerticalRewardModel(BaseRewardModel):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_size=128, dropout_prob=0.3, use_beat=True, **kwargs):\n",
    "        super().__init__(vocab_size, embedding_dim, hidden_size, dropout_prob, use_beat)\n",
    "        self.fc = nn.Linear(self.hidden_size * 3, 1)\n",
    "\n",
    "    def forward(self, human, human_lengths, machine, machine_lengths, beat):\n",
    "        human_emb = self.embedding(human)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(human_emb, human_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, human_hidden = self.gru(packed)\n",
    "        human_hidden = torch.cat([human_hidden[-2], human_hidden[-1]], dim=1)\n",
    "\n",
    "        if self.use_beat:\n",
    "            beat_emb = self.beat_embedding(beat)  \n",
    "            beat_out, _ = self.beat_rnn(beat_emb)\n",
    "            beat_feat = self.dropout(beat_out[:, -1, :])\n",
    "        else:\n",
    "            beat_feat = torch.zeros(human_hidden.size(0), self.hidden_size, device=human.device)\n",
    "\n",
    "        combined = torch.cat([\n",
    "            self.dropout(human_hidden),\n",
    "            beat_feat\n",
    "        ], dim=1)\n",
    "\n",
    "        return self.fc(combined).squeeze(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuetRangeDataset(DuetDataset):\n",
    "    def __init__(self, duet_data, window_size=5, encoding='multi'):\n",
    "        super().__init__(duet_data, encoding)\n",
    "        self.window_size = window_size\n",
    "        self.half_window = window_size // 2\n",
    "        self.valid_indices = self._generate_valid_indices()\n",
    "\n",
    "    def _generate_valid_indices(self):\n",
    "        indices = []\n",
    "        for i, entry in enumerate(self.duet_data):\n",
    "            length = min(len(entry['human']['pitch']), len(entry['machine']['pitch']), len(entry['beat']))\n",
    "            for t in range(self.half_window, length - self.half_window):\n",
    "                indices.append((i, t))\n",
    "        return indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chorale_idx, center_t = self.valid_indices[idx]\n",
    "        entry = self.duet_data[chorale_idx]\n",
    "        start = center_t - self.half_window\n",
    "        end = center_t + self.half_window + 1\n",
    "\n",
    "        try:\n",
    "            human_pitch = [self.pitch_vocab[p] for p in entry['human']['pitch'][start:end]]\n",
    "            machine_pitch = [self.pitch_vocab[p] for p in entry['machine']['pitch'][start:end]]\n",
    "        except KeyError as e:\n",
    "            raise ValueError(f\"Unknown pitch in input: {e}\")\n",
    "\n",
    "        beat = entry['beat'][start:end]\n",
    "\n",
    "        return {\n",
    "            'human_pitch': torch.tensor(human_pitch, dtype=torch.long),\n",
    "            'machine_pitch': torch.tensor(machine_pitch, dtype=torch.long),\n",
    "            'beat': torch.tensor(beat, dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_collate_fn(batch):\n",
    "    human_batch = torch.stack([item['human_pitch'] for item in batch])\n",
    "    machine_batch = torch.stack([item['machine_pitch'] for item in batch])\n",
    "    beat_batch = torch.stack([item['beat'] for item in batch])\n",
    "    seq_len = human_batch.shape[1]\n",
    "    lengths = torch.tensor([seq_len] * len(batch))\n",
    "\n",
    "    return {\n",
    "        'human_pitch': human_batch,\n",
    "        'machine_pitch': machine_batch,\n",
    "        'beat': beat_batch,\n",
    "        'human_lengths': lengths,\n",
    "        'machine_lengths': lengths\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_dataset_and_collate(train_json, val_json, model_type='joint', encoding='multi', window_size=5):\n",
    "    def load_duet_data(json_path, num_samples=100, encoding='multi'):\n",
    "\n",
    "        with open(json_path) as f:\n",
    "            chorales = json.load(f)\n",
    "        all_duets = prepare_duet_dataset(json_path, num_samples, encoding)\n",
    "        return all_duets\n",
    "\n",
    "    # Load the training and validation datasets\n",
    "    train_duets = load_duet_data(train_json, num_samples=400, encoding=encoding)\n",
    "    val_duets = load_duet_data(val_json, num_samples=40, encoding=encoding)\n",
    "\n",
    "    if model_type == 'range':\n",
    "        # For 'range' model type, use DuetRangeDataset\n",
    "        train_dataset = DuetRangeDataset(train_duets, window_size=window_size, encoding=encoding)\n",
    "        val_dataset = DuetRangeDataset(val_duets, window_size=window_size, encoding=encoding)\n",
    "        collate_fn = range_collate_fn\n",
    "    else:\n",
    "        # For other model types ('joint', 'horizontal', 'vertical'), use DuetDataset\n",
    "        train_dataset = DuetDataset(train_duets, encoding=encoding)\n",
    "        val_dataset = DuetDataset(val_duets, encoding=encoding)\n",
    "        collate_fn = custom_collate_fn\n",
    "\n",
    "    return train_dataset, val_dataset, collate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward_model(model_type, vocab_size, embedding_dim=128, hidden_dim=128, encoding='multi'):\n",
    "    if model_type == 'joint':\n",
    "        return JointRewardModel(vocab_size, embedding_dim=embedding_dim, hidden_size=hidden_dim, encoding=encoding)\n",
    "    elif model_type == 'range':\n",
    "        return JointRangeRewardModel(vocab_size, embedding_dim=embedding_dim, hidden_size=hidden_dim, encoding=encoding)\n",
    "    elif model_type == 'horizontal':\n",
    "        return HorizontalRewardModel(vocab_size, embedding_dim=embedding_dim, hidden_size=hidden_dim, encoding=encoding)\n",
    "    elif model_type == 'vertical':\n",
    "        return VerticalRewardModel(vocab_size, embedding_dim=embedding_dim, hidden_size=hidden_dim, encoding=encoding)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting training for model_type: joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [joint]: 100%|██████████| 13/13 [00:49<00:00,  3.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.1961, Val Loss = 0.0173\n",
      " Saved best model to joint_single_reward.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [joint]: 100%|██████████| 13/13 [00:48<00:00,  3.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.0068, Val Loss = 0.0018\n",
      " Saved best model to joint_single_reward.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [joint]: 100%|██████████| 13/13 [00:51<00:00,  3.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.0013, Val Loss = 0.0006\n",
      " Saved best model to joint_single_reward.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [joint]: 100%|██████████| 13/13 [00:52<00:00,  4.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.0005, Val Loss = 0.0003\n",
      " Saved best model to joint_single_reward.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [joint]: 100%|██████████| 13/13 [00:46<00:00,  3.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 0.0003, Val Loss = 0.0002\n",
      " Saved best model to joint_single_reward.pt\n",
      "\n",
      " Starting training for model_type: range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [range]: 100%|██████████| 2504/2504 [02:39<00:00, 15.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.0009, Val Loss = 0.0000\n",
      " Saved best model to range_single_reward.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [range]: 100%|██████████| 2504/2504 [02:36<00:00, 15.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.0000, Val Loss = 0.0000\n",
      " Saved best model to range_single_reward.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [range]: 100%|██████████| 2504/2504 [02:43<00:00, 15.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.0000, Val Loss = 0.0000\n",
      " Saved best model to range_single_reward.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [range]: 100%|██████████| 2504/2504 [02:47<00:00, 14.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.0000, Val Loss = 0.0000\n",
      " Saved best model to range_single_reward.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [range]: 100%|██████████| 2504/2504 [02:43<00:00, 15.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 0.0000, Val Loss = 0.0000\n",
      " Saved best model to range_single_reward.pt\n",
      "\n",
      " Starting training for model_type: horizontal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [horizontal]: 100%|██████████| 13/13 [00:33<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.2086, Val Loss = 0.0231\n",
      " Saved best model to horizontal_single_reward.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [horizontal]: 100%|██████████| 13/13 [00:32<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.0069, Val Loss = 0.0037\n",
      " Saved best model to horizontal_single_reward.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [horizontal]: 100%|██████████| 13/13 [00:27<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.0018, Val Loss = 0.0014\n",
      " Saved best model to horizontal_single_reward.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [horizontal]: 100%|██████████| 13/13 [00:24<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.0008, Val Loss = 0.0008\n",
      " Saved best model to horizontal_single_reward.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [horizontal]: 100%|██████████| 13/13 [00:20<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 0.0005, Val Loss = 0.0005\n",
      " Saved best model to horizontal_single_reward.pt\n",
      "\n",
      " Starting training for model_type: vertical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [vertical]: 100%|██████████| 13/13 [00:30<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.1585, Val Loss = 0.0134\n",
      " Saved best model to vertical_single_reward.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [vertical]: 100%|██████████| 13/13 [00:29<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.0047, Val Loss = 0.0023\n",
      " Saved best model to vertical_single_reward.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [vertical]: 100%|██████████| 13/13 [00:23<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.0014, Val Loss = 0.0009\n",
      " Saved best model to vertical_single_reward.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [vertical]: 100%|██████████| 13/13 [00:22<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.0007, Val Loss = 0.0005\n",
      " Saved best model to vertical_single_reward.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [vertical]: 100%|██████████| 13/13 [00:22<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 0.0004, Val Loss = 0.0003\n",
      " Saved best model to vertical_single_reward.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_types = ['joint', 'range', 'horizontal', 'vertical']\n",
    "encoding = 'single'              # 'single' or 'multi'\n",
    "window_size = 16                 # Only used for 'range' model\n",
    "batch_size = 32\n",
    "num_train_samples = 400\n",
    "num_val_samples = 40\n",
    "epochs = 5\n",
    "learning_rate = 1e-3\n",
    "\n",
    "for model_type in model_types:\n",
    "    print(f\"\\n Starting training for model_type: {model_type}\")\n",
    "    \n",
    "    model_save_name = f'{model_type}_{encoding}_reward.pt'\n",
    "    log_dir = f\"runs/{model_type}_{encoding}_logs\"\n",
    "\n",
    "    train_dataset, val_dataset, collate_fn = get_dataset_and_collate(\n",
    "        'bach_train.json', 'bach_test.json',\n",
    "        model_type=model_type,\n",
    "        encoding=encoding,\n",
    "        window_size=window_size if model_type == 'range' else None\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    vocab_size = train_dataset.get_vocab_size()\n",
    "    model = get_reward_model(model_type, vocab_size, encoding=encoding).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "    criterion = nn.BCEWithLogitsLoss()  \n",
    "\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=5, delta=0.001)\n",
    "\n",
    "    def train_model(model, train_loader, val_loader, epochs, model_name):\n",
    "        best_val_loss = float('inf')\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [{model_type}]\"):\n",
    "                human = batch['human_pitch'].to(device)\n",
    "                machine = batch['machine_pitch'].to(device)\n",
    "                human_lengths = batch['human_lengths'].to(device)\n",
    "                machine_lengths = batch['machine_lengths'].to(device)\n",
    "                beat = batch['beat'].long().to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(human, human_lengths, machine, machine_lengths, beat)\n",
    "\n",
    "                loss = criterion(outputs, torch.ones_like(outputs).to(device))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    human = batch['human_pitch'].to(device)\n",
    "                    machine = batch['machine_pitch'].to(device)\n",
    "                    human_lengths = batch['human_lengths'].to(device)\n",
    "                    machine_lengths = batch['machine_lengths'].to(device)\n",
    "                    beat = batch['beat'].long().to(device)\n",
    "\n",
    "                    outputs = model(human, human_lengths, machine, machine_lengths, beat)\n",
    "                    loss = criterion(outputs, torch.ones_like(outputs).to(device))\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
    "\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), model_name)\n",
    "                print(f\" Saved best model to {model_name}\")\n",
    "\n",
    "            writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "            writer.add_scalar('Loss/validation', avg_val_loss, epoch)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            if early_stopping.step(avg_val_loss):\n",
    "                print(\" Early stopping triggered. Training stopped.\")\n",
    "                break\n",
    "\n",
    "    train_model(model, train_loader, val_loader, epochs, model_save_name)\n",
    "    writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rl phasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded reward models: 4\n"
     ]
    }
   ],
   "source": [
    "def load_reward_models(model_paths, vocab_sizes, embedding_dim=128, hidden_size=128, dropout_prob=0.3, use_beat=True):\n",
    "    reward_models = []\n",
    "    \n",
    "    for model_path, vocab_size in zip(model_paths, vocab_sizes):\n",
    "        if \"joint\" in model_path and \"range\" not in model_path:\n",
    "            model = JointRewardModel(vocab_size, embedding_dim, hidden_size, dropout_prob, use_beat)\n",
    "        elif \"range\" in model_path:\n",
    "            model = JointRangeRewardModel(vocab_size, embedding_dim, hidden_size, dropout_prob, use_beat)\n",
    "        elif \"horizontal\" in model_path:\n",
    "            model = HorizontalRewardModel(vocab_size, embedding_dim, hidden_size, dropout_prob, use_beat)\n",
    "        elif \"vertical\" in model_path:\n",
    "            model = VerticalRewardModel(vocab_size, embedding_dim, hidden_size, dropout_prob, use_beat)\n",
    "\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.eval()\n",
    "        reward_models.append(model)\n",
    "    \n",
    "    return reward_models\n",
    "\n",
    "reward_model_paths = [\n",
    "    'joint_single_reward.pt',\n",
    "    'range_single_reward.pt',\n",
    "    'horizontal_single_reward.pt',\n",
    "    'vertical_single_reward.pt'\n",
    "]\n",
    "\n",
    "reward_model_vocab_sizes = [170, 170, 170, 170]\n",
    "\n",
    "rl_reward_models = load_reward_models(reward_model_paths, reward_model_vocab_sizes)\n",
    "print(f\"Loaded reward models: {len(rl_reward_models)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "class GenerationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_size=128, dropout_prob=0.3, use_beat=True):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(384, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.use_beat = use_beat\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if self.use_beat:\n",
    "            self.beat_embedding = nn.Embedding(100, embedding_dim)\n",
    "            self.beat_rnn = nn.GRU(embedding_dim, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x, lengths, beat):\n",
    "        emb = self.embedding(x)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(emb, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, hidden = self.gru(packed)\n",
    "        hidden = torch.cat([hidden[-2], hidden[-1]], dim=1)\n",
    "\n",
    "        if self.use_beat:\n",
    "            beat_emb = self.beat_embedding(beat)\n",
    "            beat_out, _ = self.beat_rnn(beat_emb)\n",
    "            beat_feat = self.dropout(beat_out[:, -1, :])\n",
    "        else:\n",
    "            beat_feat = torch.zeros(hidden.size(0), self.hidden_size, device=hidden.device)\n",
    "\n",
    "        combined = torch.cat([hidden, beat_feat], dim=1)  \n",
    "        logits = self.fc(self.dropout(combined))  \n",
    "        \n",
    "        self.hidden_state = combined  \n",
    "        return logits\n",
    "\n",
    "    def get_hidden_state(self):\n",
    "        return self.hidden_state\n",
    "\n",
    "\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_size=128, dropout_prob=0.3, use_beat=True):\n",
    "        super().__init__()\n",
    "        self.generator = GenerationModel(vocab_size, embedding_dim, hidden_size, dropout_prob, use_beat)\n",
    "        self.critic = nn.Linear(384, 1)  \n",
    "\n",
    "    def forward(self, x, lengths, beat):\n",
    "        logits = self.generator(x, lengths, beat)  \n",
    "        hidden_state = self.generator.get_hidden_state()  \n",
    "        value = self.critic(hidden_state)  \n",
    "        return logits, value\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_machine_sequence(model, human, beat, human_lengths, max_length):\n",
    "    device = human.device\n",
    "    batch_size = human.size(0)\n",
    "    \n",
    "    generated_seq = torch.zeros(batch_size, max_length, dtype=torch.long, device=device)\n",
    "    input_seq = torch.full((batch_size, 1), fill_value=1, dtype=torch.long, device=device)  # Start token (e.g., 1)\n",
    "\n",
    "    lengths = torch.full((batch_size,), fill_value=input_seq.size(1), dtype=torch.long, device=device)\n",
    "\n",
    "    for t in range(max_length):\n",
    "        beat_slice = beat[:, :input_seq.size(1)]\n",
    "        \n",
    "        logits = model(input_seq, lengths, beat_slice)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        dist = Categorical(probs)\n",
    "        \n",
    "        next_token = dist.sample()\n",
    "        \n",
    "        generated_seq[:, t] = next_token\n",
    "        \n",
    "        input_seq = torch.cat([input_seq, next_token.unsqueeze(1)], dim=1)\n",
    "\n",
    "    return generated_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, step, file_path='actor_critic_model.pth'):\n",
    "    \"\"\"Saves the model and optimizer state.\"\"\"\n",
    "    torch.save({\n",
    "        'step': step,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, file_path)\n",
    "    print(f\"Model saved at step {step}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1/1000:   1%|          | 1/125 [00:08<16:33,  8.01s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0/1000, Loss: 68.0459, Reward: 7.8963, Advantage: 7.8170\n",
      "Model saved at step 8!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1/1000:   9%|▉         | 11/125 [02:02<19:13, 10.12s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10/1000, Loss: 522.8245, Reward: 85.5564, Advantage: 65.6509\n",
      "Model saved at step 88!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1/1000:  17%|█▋        | 21/125 [03:38<20:04, 11.58s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20/1000, Loss: 718.8405, Reward: 163.3009, Advantage: 96.1876\n",
      "Model saved at step 168!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1/1000:  25%|██▍       | 31/125 [05:20<14:23,  9.18s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 30/1000, Loss: 750.6978, Reward: 240.9168, Advantage: 101.1805\n",
      "Model saved at step 248!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1/1000:  33%|███▎      | 41/125 [07:50<21:02, 15.03s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 40/1000, Loss: 728.3356, Reward: 317.9006, Advantage: 93.9938\n",
      "Model saved at step 328!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1/1000:  41%|████      | 51/125 [09:54<16:56, 13.74s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50/1000, Loss: 743.6696, Reward: 395.1319, Advantage: 96.4595\n",
      "Model saved at step 408!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1/1000:  49%|████▉     | 61/125 [11:59<13:01, 12.21s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 60/1000, Loss: 755.5392, Reward: 472.0291, Advantage: 98.4309\n",
      "Model saved at step 488!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1/1000:  57%|█████▋    | 71/125 [13:25<08:28,  9.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 70/1000, Loss: 764.1064, Reward: 550.0170, Advantage: 99.9388\n",
      "Model saved at step 568!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1/1000:  65%|██████▍   | 81/125 [15:55<09:01, 12.30s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 80/1000, Loss: 765.6618, Reward: 628.5704, Advantage: 99.8072\n",
      "Model saved at step 648!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1/1000:  73%|███████▎  | 91/125 [17:58<07:49, 13.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 90/1000, Loss: 762.1894, Reward: 706.3564, Advantage: 98.0300\n",
      "Model saved at step 728!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1/1000:  81%|████████  | 101/125 [20:08<05:47, 14.48s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100/1000, Loss: 773.3123, Reward: 785.3148, Advantage: 99.7287\n",
      "Model saved at step 808!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1/1000:  89%|████████▉ | 111/125 [21:50<02:09,  9.22s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 110/1000, Loss: 769.4518, Reward: 862.7635, Advantage: 98.5619\n",
      "Model saved at step 888!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1/1000:  97%|█████████▋| 121/125 [24:31<00:51, 13.00s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 120/1000, Loss: 777.6839, Reward: 940.1933, Advantage: 99.4445\n",
      "Model saved at step 968!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1/1000:  99%|█████████▉| 124/125 [25:05<00:12, 12.14s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Total Loss: 780.8177, Total Reward: 971.4038, Total Advantage: 99.9698\n",
      "Model saved at step 1000!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_actor_critic(model, reward_models, optimizer, dataloader, num_steps=1000, gamma=0.99, lam=0.95, save_interval=10):\n",
    "    total_loss = total_reward = total_advantage = 0\n",
    "    step = 0\n",
    "\n",
    "    total_samples = 0\n",
    "\n",
    "    while total_samples < num_steps:\n",
    "        for batch in tqdm(dataloader, desc=f\"Step {step + 1}/{num_steps}\", unit=\"batch\"):\n",
    "            human = batch['human_pitch']\n",
    "            beat = batch['beat'].long()\n",
    "            human_lengths = batch['human_lengths']\n",
    "            max_machine_len = human.size(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            machine = generate_machine_sequence(model.generator, human, beat, human_lengths, max_machine_len)\n",
    "            machine_lengths = torch.full((human.size(0),), max_machine_len, dtype=torch.long)\n",
    "\n",
    "            logits, values = model(machine, machine_lengths, beat)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            dist = Categorical(probs)\n",
    "            actions = dist.sample()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                reward_list = []\n",
    "                for rm in reward_models:\n",
    "                    rm.eval()  \n",
    "                    reward = rm(human, human_lengths, machine, machine_lengths, beat)\n",
    "                    reward_list.append(reward)\n",
    "            \n",
    "            weights = torch.tensor([0.40, 0.1, 0.2, 0.3], device=human.device)\n",
    "            stacked_rewards = torch.stack(reward_list)\n",
    "            weighted_average_rewards = (stacked_rewards * weights.view(-1, 1)).sum(dim=0)\n",
    "            final_rewards = weighted_average_rewards / weights.sum()\n",
    "\n",
    "            advantages = final_rewards - values.squeeze()\n",
    "            log_probs = dist.log_prob(actions)\n",
    "            policy_loss = -(log_probs * advantages.detach()).mean()\n",
    "            value_loss = F.mse_loss(values.squeeze(), final_rewards.detach())\n",
    "            loss = policy_loss + 0.5 * value_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_reward += final_rewards.mean().item()\n",
    "            total_advantage += advantages.mean().item()\n",
    "            total_samples += human.size(0)\n",
    "\n",
    "            if step % save_interval == 0:\n",
    "                print(f\"Step {step}/{num_steps}, Loss: {total_loss:.4f}, Reward: {total_reward:.4f}, Advantage: {total_advantage:.4f}\")\n",
    "                save_model(model, optimizer, total_samples, file_path='actor_critic_model.pth')\n",
    "\n",
    "            if total_samples >= num_steps:\n",
    "                break\n",
    "\n",
    "            step += 1\n",
    "\n",
    "        print(f\"Epoch {step // len(dataloader)} - Total Loss: {total_loss:.4f}, Total Reward: {total_reward:.4f}, Total Advantage: {total_advantage:.4f}\")\n",
    "\n",
    "    save_model(actor_critic_model, optimizer, total_samples, file_path='actor_critic_model_final.pth')\n",
    "\n",
    "\n",
    "vocab_size = 128  \n",
    "embedding_dim = 128\n",
    "hidden_size = 128\n",
    "dropout_prob = 0.3\n",
    "use_beat = True\n",
    "\n",
    "actor_critic_model = ActorCritic(vocab_size, embedding_dim, hidden_size, dropout_prob, use_beat)\n",
    "\n",
    "train_dataset = load_duet_data('bach_train.json', num_samples=1000)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "optimizer = optim.Adam(actor_critic_model.parameters(), lr=1e-3)\n",
    "train_actor_critic(actor_critic_model, rl_reward_models, optimizer, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, optimizer, file_path='actor_critic_model_final.pth'):\n",
    "    checkpoint = torch.load(file_path, map_location='cpu')  # Change to 'cuda' if using GPU\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    print(f\"Model loaded from {file_path}\")\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_from_input(model, human_pitch, beat_seq, device='cpu'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    human_pitch = human_pitch.to(device)\n",
    "    beat_seq = beat_seq.to(device)\n",
    "    \n",
    "    human_lengths = torch.tensor([human_pitch.size(1)]).to(device)  # (1,) assuming batch size 1\n",
    "\n",
    "    # Generate autoregressively\n",
    "    generated_machine = generate_machine_sequence(model.generator, human_pitch, beat_seq, human_lengths, max_length=human_pitch.size(1))\n",
    "    return generated_machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human_pitch shape: torch.Size([1, 252])\n",
      "beat_seq shape: torch.Size([1, 252])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_25680\\4259952465.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  beat_seq = torch.tensor([beat_seq], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def generate_bach_like_melody(num_bars=63):  \n",
    "    scale = [60, 62, 64, 65, 67, 69, 71, 72]  \n",
    "    melody = []\n",
    "    for _ in range(num_bars):\n",
    "        phrase = np.random.choice(scale, size=4, replace=True)\n",
    "        phrase = np.clip(np.convolve(phrase, [1, 1], mode='same') // 2, min(scale), max(scale))\n",
    "        melody.extend(phrase)\n",
    "    return melody\n",
    "\n",
    "beat_seq = np.tile([1, 2, 3, 4], 63)  \n",
    "\n",
    "human_pitch = torch.tensor([generate_bach_like_melody()], dtype=torch.long)\n",
    "beat_seq = torch.tensor([beat_seq], dtype=torch.long)\n",
    "\n",
    "print(\"human_pitch shape:\", human_pitch.shape)\n",
    "print(\"beat_seq shape:\", beat_seq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from actor_critic_model_final.pth\n",
      "Generated Machine Pitch: tensor([[ 78, 121,  40,  74,  90,  11,  56, 123,  35,  12,  22,  17,  39,  49,\n",
      "          39,  60,  77,  69,  22,  46, 122,  42,  51,  74,   1,  66,  42,  91,\n",
      "           9, 124, 107,  68,  46, 111,  32,  94,  32, 113,  91,  16,  42,  94,\n",
      "          46,  43,  11,  11,  17,  46,  16,  51, 106,  11,  12,   9,   6,  22,\n",
      "          11,  17, 121,  24,   9,  74,  33,  13,  42,  19,  71,  45,  32,  32,\n",
      "          99,  36,  54,  28,  91,  57,  17,  41,  57, 123,  32,  55,  94,  56,\n",
      "          39,  56,  39,  25,  80, 114,  24,  36,  44,  63,  94,  55, 123,  22,\n",
      "          41, 108, 116,   4, 124,  44,  49,  16,  42,  10,  42,  33,  24,  42,\n",
      "          70,  73,  94,  16, 126, 115, 116,  57,  32,  95,  31,  53, 118,  54,\n",
      "          57, 116,  73, 127,  35,  62,  42,  33,  57,  24,  30,  34,  32, 118,\n",
      "          24,  11,  45,  17,   9,  17, 105,  17,  34,  34,  35,  51, 124,   9,\n",
      "          32,  54,  53,  40,   9,  10,  12,  79,  46,  25,  90,  80,  28,  39,\n",
      "          22,  66,   6,  91,  57, 116,  97,   9,  46,  46,  32,  46,  42,  54,\n",
      "         124,  34,  52, 116,  53,  24, 105,  53,  32,  51,  73,  17, 116,  93,\n",
      "          36,  11,  42,  94,  94,  86,  76,  57,  70,  30,  82,  24,   6,   2,\n",
      "          21, 105,  94,  42, 124,  35,  32,  62,   6,  24,  24,  42,  92,  42,\n",
      "          60, 107, 107,   6,  10,  91,  40,  90,  41,  42,  99,  99,  75,  68,\n",
      "          82,  24,  31,  39,  33,  53,  57,  30,  57,  33,   9,  73,  69,  73]])\n"
     ]
    }
   ],
   "source": [
    "actor_critic_model = ActorCritic(vocab_size=128)\n",
    "optimizer = optim.Adam(actor_critic_model.parameters())\n",
    "actor_critic_model, optimizer = load_model(actor_critic_model, optimizer, 'actor_critic_model_final.pth')\n",
    "\n",
    "machine_pitch = generate_from_input(actor_critic_model, human_pitch, beat_seq)\n",
    "print(\"Generated Machine Pitch:\", machine_pitch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Machine Pitch: ['G#2', 'C2 hold', 'A2', 'E#3', 'A-4', 'C5 hold', 'G#3', 'B#4 hold', 'D3 hold', 'D4', 'C4', 'B3 hold', 'B2 hold', 'E5 hold', 'B2 hold', 'C#3', 'A#2 hold', 'F3 hold', 'C4', 'G#4', 'B#4', 'F#2', 'A#4 hold', 'E#3', 'rest', 'B-3', 'F#2', 'A-4 hold', 'A4 hold', 'F##2', 'A-2 hold', 'F3', 'G#4', 'G5 hold', 'E3', 'E-5', 'E3', 'D2 hold', 'A-4 hold', 'B3', 'F#2', 'E-5', 'G#4', 'F#2 hold', 'C5 hold', 'C5 hold', 'B3 hold', 'G#4', 'B3', 'A#4 hold', 'A-2', 'C5 hold', 'D4', 'A4 hold', 'B4', 'C4', 'C5 hold', 'B3 hold', 'C2 hold', 'A3', 'A4 hold', 'E#3', 'E3 hold', 'D4 hold', 'F#2', 'F#4 hold', 'D#5 hold', 'C#5 hold', 'E3', 'E3', 'A-3 hold', 'C3', 'C#4', 'F#3', 'A-4 hold', 'G#3 hold', 'B3 hold', 'A2 hold', 'G#3 hold', 'B#4 hold', 'E3', 'C#4 hold', 'E-5', 'G#3', 'B2 hold', 'G#3', 'B2 hold', 'A3 hold', 'B-4', 'A5', 'A3', 'C3', 'C#5', 'D#3 hold', 'E-5', 'C#4 hold', 'B#4 hold', 'C4', 'A2 hold', 'F#5', 'E#5', 'D5', 'F##2', 'C#5', 'E5 hold', 'B3', 'F#2', 'C5', 'F#2', 'E3 hold', 'A3', 'F#2', 'D#5', 'E#4 hold', 'E-5', 'B3', 'E#2', 'A5 hold', 'E#5', 'G#3 hold', 'E3', 'E-5 hold', 'G2 hold', 'D#4 hold', 'B#3', 'C#4', 'G#3 hold', 'E#5', 'E#4 hold', 'E#2 hold', 'D3 hold', 'D#3', 'F#2', 'E3 hold', 'G#3 hold', 'A3', 'G2', 'D3', 'E3', 'B#3', 'A3', 'C5 hold', 'C#5 hold', 'B3 hold', 'A4 hold', 'B3 hold', 'D-3 hold', 'B3 hold', 'D3', 'D3', 'D3 hold', 'A#4 hold', 'F##2', 'A4 hold', 'E3', 'C#4', 'D#4 hold', 'A2', 'A4 hold', 'C5', 'D4', 'G#2 hold', 'G#4', 'A3 hold', 'A-4', 'B-4', 'F#3', 'B2 hold', 'C4', 'B-3', 'B4', 'A-4 hold', 'G#3 hold', 'E#5', 'E-4 hold', 'A4 hold', 'G#4', 'G#4', 'E3', 'G#4', 'F#2', 'C#4', 'F##2', 'D3', 'D#4', 'E#5', 'D#4 hold', 'A3', 'D-3 hold', 'D#4 hold', 'E3', 'A#4 hold', 'E#4 hold', 'B3 hold', 'E#5', 'D-5 hold', 'C3', 'C5 hold', 'F#2', 'E-5', 'E-5', 'E-3', 'A#2', 'G#3 hold', 'D#5', 'G2', 'F5', 'A3', 'B4', 'G4', 'F4 hold', 'D-3 hold', 'E-5', 'F#2', 'F##2', 'D3 hold', 'E3', 'D#3', 'B4', 'A3', 'A3', 'F#2', 'D-5', 'F#2', 'C#3', 'A-2 hold', 'A-2 hold', 'B4', 'C5', 'A-4 hold', 'A2', 'A-4', 'A2 hold', 'F#2', 'A-3 hold', 'A-3 hold', 'E#3 hold', 'F3', 'F5', 'A3', 'G2 hold', 'B2 hold', 'E3 hold', 'D#4 hold', 'G#3 hold', 'G2', 'G#3 hold', 'E3 hold', 'A4 hold', 'E#4 hold', 'F3 hold', 'E#4 hold']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "decoded_pitch_seq = [decode_pitch(token.item(), encoding='single') for token in machine_pitch[0]]\n",
    "print(\"Decoded Machine Pitch:\", decoded_pitch_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import stream, note, meter\n",
    "\n",
    "def sequence_to_stream(pitch_seq, beat_seq=None, ticks_per_quarter=4, is_single_hold=True):\n",
    "    \"\"\"\n",
    "    Convert a pitch sequence and optional beat sequence into a music21 stream.Part.\n",
    "    If beat_seq is None, assumes constant step duration.\n",
    "    \"\"\"\n",
    "    s = stream.Part()\n",
    "    s.append(meter.TimeSignature('4/4'))  \n",
    "    \n",
    "    current_pitch = None\n",
    "    duration = 0.0\n",
    "    step_duration = 1.0 / ticks_per_quarter  \n",
    "\n",
    "    for i, pitch in enumerate(pitch_seq):\n",
    "        if is_single_hold and \"hold\" in pitch:\n",
    "            duration += step_duration\n",
    "        elif pitch == 'hold':\n",
    "            duration += step_duration\n",
    "        else:\n",
    "            if current_pitch:\n",
    "                if current_pitch == 'rest':\n",
    "                    s.append(note.Rest(quarterLength=duration))\n",
    "                else:\n",
    "                    s.append(note.Note(current_pitch, quarterLength=duration))\n",
    "            current_pitch = pitch\n",
    "            duration = step_duration\n",
    "\n",
    "    if current_pitch:\n",
    "        if current_pitch == 'rest':\n",
    "            s.append(note.Rest(quarterLength=duration))\n",
    "        else:\n",
    "            s.append(note.Note(current_pitch, quarterLength=duration))\n",
    "    \n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv1248603\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv1248603_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv1248603\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACJ2BNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCM5g/y8ATVRyawAABP4A/wMAAOAAQM5gkCxapzCALAAAkC1ak1iALQAAkDVak1iANQAAkERapzCARAAAkDhauwiAOAAAkD5ak1iAPgAAkDxa4jiAPAAAkDFauwiAMQAAkDxak1iAPAAAkERak1iARAAAkEhak1iASAAAkCpapzCAKgAAkDVak1iANQCTWJA6WpNYgDoAAJAqWrsIgCoAAJArWqcwgCsAAJA1WpNYgDUAAJBEWqcwgEQAAJA0WpNYgDQAAJBLWpNYgEsAAJA0WrsIgDQAAJA7WpNYgDsAAJAqWpNYgCoAAJBLWpNYgEsAAJBEWuI4gEQAAJBEWpNYgEQAAJA7WqcwgDsAAJAsWqcwgCwAAJA+WqcwgD4AAJBHWpNYgEcAAJA8Ws5ggDwAAJA5WqcwgDkAAJA1WrsIgDUAAJAqWs5ggCoAAJA0WpNYgDQAAJA0WqcwgDQAAJAwWpNYgDAAAJA9WpNYgD0AAJA2WoGJaIA2AACQNFqnMIA0AACQS1qTWIBLAACQOFqnMIA4AACQOFq7CIA4AACQRlqTWIBGAACQUVqTWIBRAACQOVqTWIA5AACQMFqTWIAwAACQSVqnMIBJAACQS1q7CIBLAACQPFqnMIA8AACQTlqTWIBOAACQTVqTWIBNAACQSlqTWIBKAACQK1qTWIArAACQSVqnMIBJAACQO1qTWIA7AACQKlqTWIAqAACQSFqTWIBIAACQKlqnMIAqAACQOVqTWIA5AACQKlqTWIAqAACQS1qnMIBLAACQS1qTWIBLAACQO1qTWIA7AACQKVqnMIApAACQTVqnMIBNAACQNFrOYIA0AACQPFqTWIA8AACQPVqnMIA9AACQTVrOYIBNAACQM1qTWIAzAACQKlq7CIAqAACQOVqTWIA5AACQK1qTWIArAACQMlqTWIAyAACQNFqTWIA0AACQPFqTWIA8AACQOVqBnUCAOQAAkDJak1iAMgAAkDJauwiAMgAAkCtapzCAKwAAkDRak1iANAAAkD1apzCAPQAAkC1apzCALQAAkEhak1iASAAAkD5apzCAPgAAkERapzCARAAAkERak1iARAAAkEZak1iARgAAkDZapzCANgAAkDxak1iAPAAAkDpak1iAOgAAkEdauwiARwAAkE1auwiATQAAkERak1iARAAAkERak1iARAAAkDRak1iANAAAkERak1iARAAAkCpak1iAKgAAkD1ak1iAPQAAkCtak1iAKwAAkDJak1iAMgAAkD9ak1iAPwAAkE1apzCATQAAkDlauwiAOQAAkDRazmCANAAAkE1apzCATQAAkDBapzCAMAAAkCpak1iAKgAAkEtak1iASwAAkEtak1iASwAAkDNak1iAMwAAkC5apzCALgAAkEtak1iASwAAkCtak1iAKwAAkE1ak1iATQAAkDlak1iAOQAAkEdak1iARwAAkENauwiAQwAAkEtak1iASwAAkCpak1iAKgAAkCtapzCAKwAAkDRak1iANAAAkDNak1iAMwAAkEdak1iARwAAkDlak1iAOQAAkDlak1iAOQAAkCpak1iAKgAAkElak1iASQAAkCpak1iAKgAAkDFauwiAMQAAkEdak1iARwAAkEhapzCASAAAkC1ak1iALQAAkERapzCARAAAkCpazmCAKgAAkDVak1iANQAAkE1ak1iATQAAkDla9hCAOQAAkCtagYlogCsAzmD/LwA=\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv1248603_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv1248603_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beat_seq = [(i % 4) + 1 for i in range(len(decoded_pitch_seq))]\n",
    "\n",
    "reconstructed_stream = sequence_to_stream(decoded_pitch_seq, beat_seq, is_single_hold=True)\n",
    "\n",
    "reconstructed_stream.show('midi')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'generated_output.mid'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"generated_output.mid\"\n",
    "reconstructed_stream.write('midi', fp=file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
